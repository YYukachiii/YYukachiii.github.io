[{"title":"test","date":"2019-09-08T11:43:45.000Z","path":"2019/09/08/论文阅读/文本摘要/","text":"文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学引言 任务目的 从一篇或多篇主题相同的文本中抽取能够反映主题的精简压缩版本，帮助用户快速形成对特定主题文本内容的全面了解 任务分类 输入文本数量 单文本摘要方法 多文本摘要方法 抽取方式 抽取式摘要 从原文中不加修改的抽取文本片段组成摘要 生成式摘要 重新组织句子形成比抽取式摘要更加精简的形式 摘要目标 面向查询的摘要(阅读理解？问答？) 一般总结性摘要 领域需求 医学摘要 邮件摘要 …… 文章内容总结 常用数据集总结 做针对数据集的方法总结和分析 总结常用数据集和方法的研究现状、存在的问题 文本摘要常用数据集总体概况​ 文本摘要常用数据集大致可分为两类： 公用数据集 自建数据集 ​ 基于深度神经网络的文本摘要需要较大规模(十万级规模)的训练数据。 DUC/TAC 描述 人工标注的生成式摘要数据集 规模较小(百篇规模),不适用于训练深度神经网络模型 主要方法 基于图模型的方法 基于传统机器学习的方法 Gigaword 描述 由英文新闻文章组成的数据集，包括950万多个新闻源的新闻语料 生成方式 将文章的首句话与新闻提要组成生成式摘要语料库 特点 原句与摘要句都是单个句子 CNN/Daily Mail 描述 单文本摘要语料库 每篇摘要包含多个摘要句 LCSTS(Large scale Chinese Short Text Summatization dataset) 描述 短文本新闻摘要数据库 来源 新浪微博 规模 超过200万 特点 文本篇幅较短 存在噪声 以提出的方法 利用RNN提取生成式摘要 注意力机制 NLPCC(自然语言处理与中文计算会议) 背景 NLPCC是由CCF举办的自然语言文本评测会议，包括文本摘要、情感分析、自动问答等任务 在NLPCC出现的文本摘要任务均为单文本摘要 特点 新闻文本不分领域、不分类型 篇幅较长 已有方法 。。。 自建数据集及其对应方法​ 公用数据集较少，因此基于自建数据集的摘要任务，常用方法可分为： 基于统计的方法 基于图模型的方法 基于词法链的方法 基于篇章结构的方法 基于机器学习的方法 经典算法和最新方法用到的数据集​ 经典方法和最新方法大都是基于深度学习的方法，但是也包括LexRank、TextRank等经典方法。 结论 缺少大规模中文长文本数据集","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"文本摘要","slug":"文本摘要","permalink":"http://yyukachiiii.github.io/child/tags/文本摘要/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"}]},{"title":"test","date":"2019-09-08T08:19:55.000Z","path":"2019/09/08/论文阅读/阅读理解/","text":"基于深度学习的机器阅读理解综述，2019，北航引言 定义 让机器学会阅读和理解文章，对于给定的问题，从相关文章中寻找答案 设计技术 语言理解 知识推理 摘要生成 应用 智能搜索：搜索互联网的文档进行阅读理解，为用户返回更加准确和智能的答案 智能客服 发展历史 1999年开始了最早的MRC研究 传统的MRC技术大多采用模式匹配的方法进行特征提取，不能处理表达的多样性问题 先进的MRC技术采用深度神经网络进行机器阅读理解的研究 2016年斯坦福发布大规模数据集SQuAD，极大推动了MRC的快速发展 总结： 历史比较短，研究内容都比较新 基于深度学习的阅读理解 模型的组成 词向量模块 将所有单词映射到一个向量空间，包含单词的语法和语义信息，及词与词之间的关系 编码模块 以词向量表示的文本序列作为输入，通过深度神经网络对文本序列进行特征提取，含有上行下文信息和语义信息 注意力模块 从文章中挑选出与问题关联度最大的部分内容，排除不相关信息 答案预测模块 方法由抽取式逐渐发展为生成式；由单篇文章提供转向多篇文章生成 词向量模块​ 词向量的生成方式： 矩阵分解法 参数学习法 上下文学习法 参数学习法​ 常见的参数学习法： Bengio等基于神经网络的概率语言模型，将词向量作为语言模型的参数进行学习 Mikolov提出的Word2vec模型，借鉴N-gram思想，没有考虑全局信息 ​ 缺陷： 没有解决一词多义的问题 上下文学习法 参数学习法是词向量的一种静态的表示方法，同一个词汇具有相同的词向量表示 解决一词多义问题关键在于利用上下文语境，词向量是动态的模型输出 ​ 上下文学习法学习到的词向量举例： BiLSTM ELMo(Embeddings from Language Models) 注意力机制​ 处理阅读理解问题时，基于神经网络的模型几乎都使用了注意力机制。 ​ 在MRC中，根据注意力机制的结构，可分为： 单路注意力模型 双路注意力模型 自匹配注意力模型 单路注意力模型 描述： 模拟人做阅读理解的过程 只在文章上使用注意力机制 通过结合问题和文本段落二者的信息，生成一个关于文本段落各部分的注意力权重，对文本信息进行加权 双路注意力模型 描述： 同时在问题和文章上使用注意力机制 对文章和问题之间进行了细粒度的建模，一般比单路注意力模型好 自匹配注意力模型 描述 反复阅读文章并找出重点 注意力模块是机器阅读理解的核心模块，对提升模型的性能至关重要 答案预测​ 主要分类： 抽取式 生成式 答案抽取 定义 从文章中挑取答案，然后生成答案 举例 斯坦福大学的SQuAD数据集中，每个问题的答案都是原文的一个子片段，是典型的抽取式数据集 抽取模型 序列模型 边界模型 答案生成 举例 微软亚洲研究院的MS MARCO数据集，答案是人工阅读候选文章后总结生成的，不再受限于文章片段，要求模型具有生成答案的能力 实例 通过答案抽取模型从候选文章中提取线索，然后用机器翻译模型将线索翻译为答案 现状 抽取模型仍是主流，生成技术只是作为一种辅助手段产生答案 MRC面临的主要问题词向量模块仍需改善 使用预训练的语言模型取代预训练的词向量对MRC模型带来了显著的提升 但基于语言模型的词向量仍然有局限性 模型缺乏推理能力 当前的阅读理解模型仍不具备推理能力，而是注意某些线索以执行粗浅的模式匹配 模型缺乏外部知识 模型的信息均来自于文章，没有结合外部知识 答案生成技术研究不足 当前的答案生成技术仍然以抽取式为主，因此在SQuAD数据集上取得了成功 但是在MS MACRO等贴近真实应用场景的数据集仍效果欠佳 MRC的发展趋势 构建端到端的高效模型 深层结构探索，提高推理能力 与其他NLP技术进行结合 外部知识库 指代消解 答案生成技术的深入研究 对多候选文章进行排名 问题 什么是预训练语言模型？ 最新的SQuAD数据集由500+文章和10,0000+问题组成，训练集20MB左右，发展集4MB左右，仅训练数据来看并不大","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"},{"name":"阅读理解","slug":"阅读理解","permalink":"http://yyukachiiii.github.io/child/tags/阅读理解/"}]},{"title":"test","date":"2019-09-08T07:07:34.000Z","path":"2019/09/08/论文阅读/自动问答/","text":"自动问答综述，2002，哈尔滨工业大学引言 传统的搜索引擎的不足 相关性信息太多 检索需求无法以几个关键字的逻辑组合来完全表达 以关键字为基础的索引停留的语言层面，没有涉及到语义 自动问答系统 为了改进搜索引擎的弊端发展而来 问答系统就是新一代的搜索引擎 研究概况 早起(上世纪80年代)的问答系统一直被限制在特殊领域的专家系统 组成(三个部分)： 问题分析：理解用户的问题是什么 问题分类 关键词提取 关键词扩展 信息检索：在已有的文档中查找和关键词集相关的文档 答案抽取：从信息检索中返回的网页中抽取答案 最为影响整个问答系统准确性的部分 常问问题(FAQ)库：常问问题可以直接从库中检索并返回 问题分析​ 需要完成的任务： 确定问题的类型 提取出问题的关键词 依据问题的类型对关键词进行适当的扩展 问题分类​ 针对不同类型的问题，有不同的处理方法，例如询问人、询问时间、询问数量等等。 ​ 对问题分类之后，在针对不同的问题类型，制定不同的答案抽取规则。 ​ 问题分类有两种方法： 按照事先规定好的类别进行分类 使用机器学习算法自动分类 关键词提取​ 在问题中，提取出对检索有用的关键字。关键词能够提高检索系统的准确性。 关键词扩展​ 答案中的词常常不是问题的关键词，而是关键词的同义扩展。 ​ 关键词扩展虽然能够提高系统的召回率，但是扩展不当却会降低检索的正确率。 信息检索模块 任务 用前面提取出的关键字到文档库中查找相关的文档 信息检索模块的建立 对文档库进行预处理(汉语要分词、英语要Stemming) 对文档库建立索引 返回内容 文档、段落或句子 答案抽取 任务 将信息检索模块搜索出来的相关文档抽取答案 以句子作为答案​ 步骤如下：（类似于文本摘要呀） 把检索出来的文档分成句子 按照一定的算法，计算每个句子的权重 对句子按照权重进行排序 根据问题的类型对候选答案重新排序 以词或短语作为答案以文摘作为答案​ 多文档自动摘要技术，把相关文档做成文摘，在把文摘返回给用户。 评价​ 建立测试集，将系统对测试集问题得到的回答与人工答案进行对比，计算出问答系统的准确率。 结论 当前(2002年)的问答系统不具备思维和推论能力，只是从文档库中搜索相关的答案。自动问答技术处于起步阶段。","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"},{"name":"问答系统","slug":"问答系统","permalink":"http://yyukachiiii.github.io/child/tags/问答系统/"}]},{"title":"Chapter 1.基础介绍","date":"2019-09-06T13:20:36.000Z","path":"2019/09/06/NLP/Chap.1/","text":"Chapter 1.基础介绍The Supervised Learning Paradigm（范例）符号表示 输入(观察值)：$x$ 类别标签(ground truth)：$y$ 类别的预测：$\\hat{y}$ 有价值的内容 实际应用中很少使用随机梯度下降(SGD),因为收敛非常慢 Observation And Target Encoding文本的向量表示的方法 One-Hot Representation 表示成句子或文档长度乘以词表大小的矩阵 表示成一个词汇表长度的向量(一般都是使用这种表示吧…) TF Representation TF表示是构成句子的词的one-hot的总和，即向量中每个条目是相应单词在句子中出现次数的计数 TF-IDF(Inverse Document Frequency) Representation 在TF表示的基础上，惩罚出现次数更多地条目，奖励罕见的符号 这样的启发式表示(?什么是启发式表示？？？)在深度学习中很少使用 Target Encoding 按照目标任务的具体情况选择文本的向量表示 Word Embedding 词向量的分布式表示 Computional Graphs 在计算图中，结点是乘法和加法等数学运算，输入是节点的传入边，输出是结点的传出边。 PyTorch Basics动态计算图 分类 TensorFlow Caffe(贾扬清开发的深度学习框架) Theano 特点 在计算之前，需要声明、编译和执行计算图 计算效率高，在生产中非常有用 静态计算图 分类 PyTorch Chainer DyNet 特点 更加灵活，不需要在每次执行(计算)之前再进行编译 每个输入(什么意思?)可能导致不同的图结构 张量 定义 零阶张量：标量(数字) 一阶张量：向量（数字数组） 二阶张量：矩阵（向量数组）","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://yyukachiiii.github.io/child/tags/PyTorch/"}]},{"title":"nexmoe","date":"2019-08-29T01:16:49.000Z","path":"2019/08/29/nexmoe/","text":"​ 从零开始学习创建基于hexo框架的主题模型。 前置知识模板引擎定义 模板引擎是为了使用户界面与业务数据（内容）分离而产生的，它可以生成特定格式的文档，用于网站的模板引擎就会生成一个标准的文档. ​ 简单来说，就是将模板文件和数据通过模板引擎生成一个HTML代码。能够让动态页面在渲染的时候，能够简化字符串的拼接操作。 分类 ejs EJS 是一套简单的模板语言，帮你利用普通的 JavaScript 代码生成 HTML 页面。 CSS定义 层叠样式表(Cascading Style Sheets)是一种用来表现HTML（标准通用标记语言的一个应用）或XML（标准通用标记语言的一个子集）等文件样式的计算机语言。 CSS预处理器定义 CSS预处理器是用一种专门的编程语言，进行Web页面样式设计，然后再编译成正常的CSS文件，以供项目使用。 与CSS的关系​ 使用CSS语言之外的语言进行网页样式设计的代码，经过预处理器处理后，转换为标准CSS文件。 代码答疑HEXO辅助函数模板partial 作用：载入其他模板文件，在该代码的位置插入模板文件的代码 代码：&lt;%- partial(layout, [locals], [options]) %&gt; 详细信息 ejs相关代码 &lt;% %&gt;的作用？ 在写网页代码时，有时需要用JavaScript的逻辑代码来渲染页面，但是JavaScript的代码与HTML的代码是不一样的，不好区分。 因此使用&lt;% %&gt;来包裹住逻辑代码，方便与HTML代码进行区分。","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yyukachiiii.github.io/child/tags/hexo/"}]},{"title":"hexo主题","date":"2019-08-28T13:20:36.000Z","path":"2019/08/28/hexo主题/","text":"","tags":[]}]