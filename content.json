[{"title":"test","date":"2019-09-22T03:09:27.000Z","path":"2019/09/22/test/","text":"我看看到底行不行？","tags":[]},{"title":"己亥年八月廿三日随笔","date":"2019-09-21T04:56:46.000Z","path":"2019/09/21/随笔/己亥年八月廿三日随笔/","text":"​ 世界上只有一种真正的英雄主义，那就是在认清生活的真相以后仍然热爱生活。 ——罗曼罗兰","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yyukachiiii.github.io/child/tags/随笔/"}]},{"title":"经典文献阅读总结","date":"2019-09-20T12:25:52.000Z","path":"2019/09/20/论文阅读/经典文献阅读/Transformer/","text":"Attention is all you need一些需要查找的知识 残差链接(residual connections) 残差网络(residual networks) 单词(QWQ) correspond to 相当于 in addition to 此外 Attention​ 这里的query，key,value分别是指什么呢？ value我猜是每个输入的embedding，且每一个的维度是$d_v$,key是每个输入的权重，维度是$d_k$，那query呢？ ​ 我觉得我不理解的原因还是在于，对于Attention，我都没有完全的搞明白，具体的每一个计算过程都没有搞明白。 Scaled Dot-Product Attention 这个attention机制被称作”Scaled Dot-Product Attention” attention机制的输入 query key value 步骤 query和key的维度都是dk,key和value是一一对应的，所以key有很多个。 query与多个key一一点乘，得到key的数量个值，把他们除以$\\sqrt{d_{K}}$， 上一步的结果经过softmax层变换，得到了关于每个value的权值 在实践中，多个query，key和value都是组织称矩阵的形式，整个attention子层的计算公式如下 Attention $(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V$ 评价 比起两种广泛使用的attention计算方法(additive attention 和 dot-product attention)， 该计算公式具有更加快速和节省空间的效果 Multi-Head Attention​ 对这些query，key和value，通过学习得到的不同的线性投影h个，得到h个不同的版本。对每一个版本都分别计算attention，得到H个不同的结果。得到的结果再经过concatenate和投影(project)，得到最终的结果。 ​ Multi-Head Attention 的公式表示如下：$$\\begin{aligned} \\text { MultiHead }(Q, K, V) &amp;=\\text { Concat }\\left(\\text { head }{1}, \\ldots, \\text { head }{\\mathrm{h}}\\right) W^{O} \\ \\text { where head }{\\mathrm{i}} &amp;=\\text { Attention }\\left(Q W{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\\right) \\end{aligned}$$ Applications of Attention in our Model​ Transformer的三种不同的使用多头自注意力的方式： 在”encoder-decoder attentioin”层，query来自上一个decoder层，key和value来自Encoder的输出。 在Encoder中的每一个self-attention层，它的key、value和query都来自Encoder中上一个层的输出。 没太看懂… …. Position-wise Feed-Forward Nerworks​ 这个额外的前馈层公式如下：$$\\operatorname{FFN}(x)=\\max \\left(0, x W_{1}+b_{1}\\right) W_{2}+b_{2}$$​ 由公式可知，在两个线性层之间添加了一个ReLUctant激活函数。输入和输出的维度均为$d_{model}$512，中间层的维度是$d_{ff}$2048. Embedding and Softmax​ 没看懂… …. Positional Encoding​ 因为本模型(Transformer)没有利用序列顺序的信息，于是添加了对”input embeddings”添加了位置编码信息。 ​ 后面的还是看不太懂……","tags":[{"name":"经典文献阅读","slug":"经典文献阅读","permalink":"http://yyukachiiii.github.io/child/tags/经典文献阅读/"},{"name":"transformer","slug":"transformer","permalink":"http://yyukachiiii.github.io/child/tags/transformer/"}]},{"title":"对话系统构建方法分析","date":"2019-09-19T07:38:52.000Z","path":"2019/09/19/论文阅读/对话系统方法分析/","text":"任务型对话任务型对话总体结构基于管道的方法​ 任务型对话的一种经典的解决方案，主要结构包括： 自然语言理解 对话管理 对话状态追踪 对话策略学习 自然语言生成 自然语言理解 输入：用户的语句 任务(依次完成) 槽标记(slot tagging) 对句子中的语义槽序列进行标记 语义槽是根据不同的场景预先定义的 大量基于深度神经网络的方法被应用到这个问题上 流程 输入：句子序列 输出：一个语义槽(slot)/语义标记(semantic label)序列 语义槽 句子级别 用户需求类型 语句类型 词语级别 实体识别 语义槽填充 领域识别(domain detection) 将用户的服务需求划分到某一事先定义好的领域下 意图理解(intent determination) 针对用户的表述中的显示意图和隐示意图做出识别和理解 显示意图：包括用户的某些明确的需求 隐示意图：在表达中隐性包含的需求，可能需要结合上下文综合判断 衡量指标 准确率 F1评分 地位 对话系统中的预处理模块 总结 领域识别和意图理解都是分类问题，可以使用RNN，CNN等来解决 三个任务可以一起进行训练，如可将LSTM用于三个任务的联合训练模型上 对话状态追踪 背景 NLU处理过后，形成一个包含用户在本轮对话中所有需求信息的状态信息 地位 确保对话系统健壮性的核心组成部分 核心(这一个部分完成什么东西，做什么) 利用对话中的信息对预定义的对话的细节框架进行填充 当框架中存在未能填补完成的细节时，系统会向用户做出进一步询问 技术 早期以规则为主 CRF等的统计学习方法 神经网络(DNN、CNN、RNN) 对话策略学习​ 学习如何通过当前的对话状态的表征，生成抽象的对话策略，在之后的NLG过程中，能够直接通过这个过程的结果生成对话。 目的 从对话状态表征中学习出一定的对话模式，作为指导人机对话生成的策略 完成系统从理解识别到生成对话的转换 利用当前对话状态的表征向量产生下一步最优的回复 解决方案 监督学习 强化学习 特点 学习出一个好的对话生成策略需要大量的训练数据支持 可以通过专家系统的规则作为处事策略进行训练，从而加快模型的训练速度 现状 端到端的强化学习比起监督学习，在各种策略学习中都有较好的结果(？怎么个端到端？) 自然语言生成 目的 将基于抽象的对话策略做出的决策装换成自然语言表述的句子 地位 对于对话系统的自然度有着极为重要的影响 极大地影响人机对话系统的用户体验 解决方案 基于模板和规则 生成效果精确 领域局限性过强，且可扩展性差 基于数据驱动 将检索方法和统计学习相结合 依旧不够灵活 基于深度学习(基于深度学习不也是基于数据驱动的吗) 基于SC-LSTM的方法 使用分层方法进行改进等 基于端到端的方法​ 基于端到端的任务型对话这篇论文中介绍的很少，还是需要参考更多的文章。 基于管道的特点 模块化，构建灵活，分类优化 系统整体优化困难 基于端到端的特点 能够利用更为海量的数据和强大的计算力 可扩展性得到了提升 规避认为特征工程带来的不确定性和工作量 不仅适用于任务型对话系统，对非任务型对话系统同样有很好的结果 基于端到端的缺陷 训练数据过于庞大 单纯使用这一结构会导致对话策略的学习中对对话控制的能力偏弱 论文思路研读基于知识图谱的保险领域对话系统构建关键字 基于管道 保险领域 知识图谱 模型结构细节NLU 基于语义模板的语义分析模型 流程： 自然语言预处理，得到分词后的字符串流 字符串流和模板库中的模板进行匹配，得到对话意图(通过模板的形式，将用户的意图映射到知识图谱上，从知识图谱中得到答案用户意图) 对话管理 作用 处理对话的上下文信息(对话状态追踪)，进行相应的逻辑运算并返回回答结果的表达式(对话策略生成过程) 对话模型 基于有限状态自动机的对话模型 自动机根据NLU过程的结果判断下一个状态(即应该做什么，具体规则见论文) 结合填表的方法构建对话管理模块 表格用来维护上下文信息 数据集​ 手动收集，9000条用户真实数据上进行实体和意图的标注，构建了800个语义模板。 评价 NLU是基于模板的 对话状态追踪是基于自动机 对话策略生成式基于规则的 NLG也是基于模板的 有点笨，需要手动生成800个模板才能够达到比较好的效果，不太喜欢 基于克服场景的智能对话系统的设计与实现关键字 智能客服 基于管道 总体描述 结合了多种处理方式(检索方法，任务流程处理方法，神经网络匹配，端到端生成) 框架 文本预处理 NLU 信息抽取 意图识别 DM DST Policy NLG 对话管理模块继承了不同的对话机器人 QA-Bot Task-Bot Seq2seq-Bot 模型结构细节数据处理模块​ 数据是公开的淘宝客服的对话数据。 分词和归一化(文本怎么归一化？) 对数据、日期等信息进行正则过滤 丢弃短回复、清理低频回复 自然语言理解模块 槽填充 意图识别 对话管理模块​ 设计了三种对话Bot。(怎么设计的DST和Policy模块呢？) QA-Bot 使用了信息检索的方法 具体的内容没有提及太多。我的理解是这是个基于检索的对话模块，根据语料库中的对话，通过检索得到回复 Task-Bot ·针对一些可以流程化处理的任务 并没有提及细节 Seq2seq模块 采用比较通用的biLSTM结构 仍然没有说这个模块更多地细节 NLG模块​ 综合上述三个Bot给出的回复，根据策略选择得到系统认为的最佳回复。 ​ 并不是一个将抽象的语义向量转换为自然语言的过程。而是在对话管理模块就已经产生了自然语言的回复，在这个任务这个模型中，NLG模块只是一个筛选的过程。 评估方法 Recall@k 给定一个问题选择k个最有可能的回答，检测正确的回答在不在这k个回答里 使用Ubuntu Corpus数据集作为测试集 评价 只是说了一下大体的流程，即基于管道，即对话管理模块使用了三个bot，几乎没有一点细节 对于如何实现一无所知 基于小样本机器学习的跨任务对话系统关键词 预训练特诊(什么是预训练特征，怎么用？) 小样本(为了增强扩展性和降低收集数据的难度) 描述 目标是将学习的行为能够从一个槽填充任务迁移到另一个槽填充任务(什么是迁移？) 对话系统中任务与非任务对话交错的情形(这个挺有意思的) 模型结构细节框架 自然语言理解模块 状态跟踪器(跟踪对话状态，怎么跟踪？) 对话策略(接收当前的跟踪器状态，选择下一步采取什么行为) 自然语言生成(选定的行为作为对话状态的一部分被记录到跟踪器中) 自然语言理解​ 主要包含语义槽填充和意图分类两个任务。语义槽填充相当于一个序列标注任务，而意图分类可看做一个文本分类任务。 利用BERT作为预训练模型，将语句嵌入的特征作为意图识别的分类依据 BERT模型能够直接覆盖序列标注、文本分类、句子关系判断等类型的下游任务，因此本文使用BERT完成意图识别和槽填充任务 对话管理模块 基于神经图灵机的循环嵌入对话策略 看不懂QAQ脑子有点懵了，我去看别的论文吧QAQ 自然语言生成模块 基于应答模板 对于闲聊类型的用户输入，调用了一个外部闲聊系统 开放领域对话说实话，我怎么感觉挺一般的，红轴的键盘不过如此。切，不过如此呀，我原以为有多么好用呢 不过话说回来，感觉还的确挺不错的。 嗯，挺香的 。","tags":[{"name":"对话系统","slug":"对话系统","permalink":"http://yyukachiiii.github.io/child/tags/对话系统/"}]},{"title":"用PyTorch学习NLP Chapter 4.前馈网络","date":"2019-09-17T01:15:36.000Z","path":"2019/09/17/NLP/Chap.4/","text":"​ 感知器是最简单的神经网络。它只能够进行线性可分的数据分类。这一章探索两种前馈神经网络：多层感知器和卷积神经网络。前馈神经网络和递归神经网络(RNNs)形成对比，递归神经网络允许反馈，这样没次计算都可以从之前的计算中获得信息。 The Multilayer Perceptron","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://yyukachiiii.github.io/child/tags/PyTorch/"}]},{"title":"己亥年八月十四日随笔","date":"2019-09-12T11:36:12.000Z","path":"2019/09/12/随笔/己亥年八月十四日随笔/","text":"​ 今天查论文的时候无意中发现了一篇关于HanLP的报道，才得知博客hankcs的作者的名字是何晗，现在是大快搜索的高级研究员。 ​ 第一次发现hankcs的博客还是在自学斯坦福的cs224n课程深度自然语言处理的时候，当时就被作者清晰的思路、博客内容的详细和这其中透露出的作者不俗的功底留下了深刻的印象。同时这位大佬也学过日语，这让当时正在自学日语的我更加向往。 ​ 大佬的每篇博客都非常非常的认真，贴出了大量的图片和详尽的公式推理。涉及的内容也非常广，从NLP、机器学习，到C++、Java，到算法，到自己写的一些小程序，再到日语，且每一篇博客都整理的非常认真，这在我自己开始写博客之后有了更加深刻的理解，一个每一篇博客都认认整整的整理的人，作别的事情一定也是无比认真的，而我却恰恰相反，学习知识不求甚解，作业得过且过，难怪自己学习了一年却感觉非常没有底气。从小没有任何偶像概念的我，这个时候产生了要成为何晗大佬这样的人的想法。 ​ 除了专业知识扎实之外，网址还有自己的logo(一只蓝色的蝴蝶)，连我这个自认为对这种事物非常挑剔的人都觉得非常漂亮。那时并不知道大佬的底细，只能够根据从大佬博客、Twitter、微博中看到的消息，自己脑补大佬酷炫的人生。 ​ 在大佬的感召下，我也开始搭建自己的博客，整理自己学习心得，顺便也想写写文章，记录下自己的成长。看着自己写的学习笔记，与大佬一比之下果然相形见绌，没有那种简洁又清晰的感觉。于是对大佬的仰慕又多了一分。 ​ 到今天为止，看大佬的博客已经有半年了，大佬一度成为我的奋斗奋斗目标，我多么希望自己也能够成为大佬那样全能的人呀！我一直认为自己是和大佬在很多方面颇为相似的人，因此单方面与大佬神交已久。希望有一天，能够和大佬成为朋友，亲口听大佬将他自己的成长故事。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yyukachiiii.github.io/child/tags/随笔/"}]},{"title":"记录一下自己的学习进度","date":"2019-09-11T13:06:04.000Z","path":"2019/09/11/随笔/学习记录/","text":"2019.9.11 完成了Learn NLP with PyTorch第三章的阅读笔记，简单看了一下用PyTorch解决NLP问题的标准流程，但许多细节不懂 继续选题，阅读并完成了一篇综述和一篇基于中文歌词的情感分类的笔记，仍然没有什么好的想法 Learn NLP with PyTorch这本书该怎么利用，代码光看是没用的，该怎么利用？ 2019.9.12 没看论文 主要是在看基于PyTorch的评论分类任务的代码，除去tqdm部分的代码，其余的都已经看懂了，但是缺少实践 终于知道了hankcs大佬的来历了 2019.9.13~2019.9.15 啥也没干 2019.9.16 又看了一遍Learn NLP With PyTorch第三章使用感知机进行文本情感分类的代码，加深了一下印象 继续阅读情感摘要的论文，并进行记录 有了一些新的想法，例如不一定要直接做情感分析，可以做基于情感分析的推荐系统、预测系统等等 2019.9.17 Learn NLP with PyTorch 第四章看了关于MLP多层感知机的内容，简单利用PyTorch实现了两层的MLP，并开始看使用MLP进行人名分类(国籍)的代码，还有很多细节没有搞明白 看论文，详细阅读了一篇多轮对话的综述，了解了任务型和非任务型对话的基本实现方法 看了一些对话系统实现的摘要，有了一些简单的了解 2019.9.18 Learn NLP with PyTorch 第四章 开始上手写代码，上午完成了姓名分类的数据集的预处理代码… … 看论文，一篇产自北京大学的非常全面的开放领域的人机对话系统的综述文章，学到了很多东西 尝试查找一篇任务型对话的综述文章，但是没有找到… …实在找不到的话，应该考虑其他的方法了QAQ 2019.9.19 Learn NLP With PyTorch 第四章继续写代码，完成了Vocabulary类和Vectorizer类的大部分代码(暂时用不到的类方法都没写)，并且成功进行了测试 看论文，重新仔细阅读了对话系统综述的面向任务型对话的综述部分，主要介绍了基于管道的方法，端到端的内容涉及较少 看论文，找了两片最新的工程实现的文章，第一篇来自清华大学，保险领域基于知识图谱和管道的对话系统，各个模块全都是基于模板和规则的，感觉有点笨；第二篇文章来自上大和中大，是客服领域基于管道的对话系统，框架比较主流，但DM模块一共设置了三个BOT，最终回复从产生的结果中进行筛选，缺少细节。 报名参加了CCF BDCI的两个比赛，现在一是实力不济，二是也没时间做，等确定好题目，完整的写完一遍使用PyTorch进行NLP任务的框架后就着手开始 发现了一个交流经验(看论文、数据预处理等等)的好地方，CCF BDCI官网的一个问答区，了解还不是很多，但是感觉里面的质量非常可以","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yyukachiiii.github.io/child/tags/随笔/"},{"name":"学习记录","slug":"学习记录","permalink":"http://yyukachiiii.github.io/child/tags/学习记录/"}]},{"title":"情感分析论文阅读","date":"2019-09-11T08:45:26.000Z","path":"2019/09/11/论文阅读/情感分析/","text":"文本情绪分析综述，2018，中科院，中国科学院大学引言​ 文本情绪分析技术可以帮助研究机构、信息咨询组织和政府决策部门掌握社会情绪动态，这种需求极大地促进了情绪分析技术的发展。 ​ 情绪分析又称为细粒度类别的情感分析，情感分析也可以看做二分类的情绪分析。情绪分析是在现有粗粒度的二分类分析工作的基础上，从人类的心理学角度出发，多维度的描述人的情绪态度。 背景知识​ 情绪，是多种感觉、思想、行为综合产生的生理和心理状态，是对外界刺激所产生的生理反应。情感是多种情绪的综合表现，而情绪是情感的具体组成。 情绪分类理论​ 美国心理学家Ekman提出一个基础情绪理论，认为基本情绪包括高兴(joy)、悲伤(sadness)、愤怒(anger)、恐惧(fear)、厌恶(disgust)和诧异(surprise)。 ​ 美国心理学家Plutchik在此基础上提出的一个情绪模型定义了8中基本双向情绪，包括前六种以及信任(trust)、期望(anticipation)。 ​ 此外，从分层的角度出发，英国心理学家Parrott提出了一种基于树结构的情绪分类模型，由6种基本情绪组成，分别为爱(love)、高兴(joy)、诧异(surprise)、愤怒(anger)、悲伤(sadness)和恐惧(fear)。 文本情绪分析应用舆情监控​ 所谓网络舆情，就是对社会热门问题持有不同看法的网络舆论，是社会舆论的一种表现形式，是公众通过互联网对现实生活中某些热点、焦点问题发表具有较强影响力、倾向性的言论和观点。 商业决策​ 商品评论分析。 观点搜索​ 用户在海量信息中的搜索过程中同时考虑关键字和哟用户的情感需求，能够使搜索变得更加便捷、准确和智能。 ​ 任务是从海量文本信息中查询文本所蕴含的观点，并根据主题相关度和观点倾向性的结果进行排序。 信息预测​ 通过对微博上新闻、评论等信息进行分析，预测事件的发展趋势。 金融预测​ 例如通过对股票的评论的分析，能够在一定程度上预测股市变化的趋势。 选情预测​ 例如通过分析Twitter上各竞选团队的评论，制定针对摇摆州的特定宣传政策；通过对网络新闻的分析，预测大选的结果等。 其他预测​ 还可以用于对政策性时间的民意预测。 ​ 这个我觉得挺有意思的。 情绪管理​ 通过对用户情绪分析，可以让用户更加了解自我，从而找到更加适合自己的方式去学习、工作和生活。 情感分析​ 情感分析的任务主要包括：情感信息抽取、情感分类、情感检索与归纳。 情感信息抽取​ 包括识别情感表达者、评价对象以及情感观点等有价值的任务。 情感分类 任务： 识别指定文本的主观性观点，并判断文本情感的政府倾向性。 分类 基于词典和规则的方法 基于机器学习的方法 情感摘要和检索情感摘要 任务： 对带有情感的文本进行浓缩、提炼从而产生文本所表达的关于情感意见的摘要。 情感检索 任务： 检索和查询相关观点的文档或句子 根据主题性相关性和观点倾向性对检索出的文档或句子进行排序 情绪分析 任务： 指通过提取文本中的情绪要素，将文本划分到一个或多个预定义的情绪类别中。 基于词典和规则的情绪分类方法 能体现文本的非结构化特征 处理速度快且精度高 基于词典的情绪分类方法​ 基于词典的方法主要利用情绪词典资源，将语料库中的情绪表达关键字提取出来，并藉此对语料进行情绪分类。 基于规则的情绪分类​ 虽然基于规则的情绪方法可以在较短时间内获得分类结果，且可以加入事前起因等其他规则来提高情绪分类的准确率，但在数据量较大时，规则的维护比较复杂，且不易扩展． 基于机器学习的情绪分类方法​ 主要有有监督和半监督方法。 有监督学习情绪分类方法​ 特征选取是否合适是影响有监督学习分类效果的一个主要因素，现有方法中用于情绪分类的特征主要包括词级、句子级和篇章级特征．其中，词级特征主要包括词频（例如词袋特征）、词性（例如名词、动词、连接词）、语义（例如词向量的相似度）、表情符号及其组合等． ​ 对于微博、即时消息等短文本由于受到字数的限制，呈现出特征稀疏、内容简短、表述直接等特点，这使得其分类效果难以得到保证。 总体上，基于有监督学习的方法在准确率上优于基于词典和规则的法，但对样本数据的质量要求较高，需要花费巨大的时间成本和人力成本对语料进行标注，影响了该方法的推广． 半监督学习分类方法​ 半监督学习方法可以充分利用大量的未标记样本改善分类器性能，在情绪分类任务中扮演着重要的角色，研究者们对此开展了大量研究． ​ 该类方法的优点在于可以较方便地获得大量的标记数据用以训练样本集，解决了有标记数据集稀缺的问题．然而，该类在第１次分类过程中分错的样本，会影响到第２次分类的准确率． 复合情绪分类方法 一类是将情绪分类任务分解成有无情绪、正负情感、细粒度情绪等子任务，在分别针对不容子任务设计不同算法 另一类基于子类的复合方法是将语料库先分为更细致的子类，再利用分好的子类对样本进行分析，从而获得最终的情绪分类 ​ 归纳上述３类方法，主要是针对极性或单一情绪标签分类，忽略了情绪标签在实例中多情绪共存的情况．因此，情绪分析与传统的情感分析相比，从另一个维度还可以看作是一个多标签情绪分类问题． 其他情绪分类方法​ 传统的情绪分析方法很少认为一个文本可以同时表达多种情绪，而事实中一条语料可能出现有多种情绪共存的情况．为了更准确地把握文本中所表达的情绪信息，研究者们从另一个新的维度出发，开展了基于多标签情绪分类的研究． 研究展望面临的挑战数据稀缺性​ 无论是情绪训练语料还是情绪词典资源，都处于比较匮乏的阶段。 类别不平衡​ 收集到的样本中情绪各类别的数量明显存在差异。 领域依赖性​ 情绪词在不同领域的表达存在差异 未来研究方向​ 未来文本情绪分析的研究还需要关注如下几个方面： 基于多媒体融合的情绪分析 基于领域自适应的情绪分析 基于社交网络分析的情绪分析 基于深层语义的情绪分析 ​ 文本情绪分析的新的应用需求： 面向大数据的文本情绪费 面向特定主题的情绪分析 面向个性化的情绪分析 面向多语言的情绪分析 总结文本情绪分析作为自然语言处理和文本挖掘中一个新兴的研究方向，有着很广泛的应用前景．情感分析的研究已经比较成熟，而情绪分析的研究尚处于起步阶段，且国内研究较少．","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"情感分析","slug":"情感分析","permalink":"http://yyukachiiii.github.io/child/tags/情感分析/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"}]},{"title":"一些感兴趣方向的论文阅读","date":"2019-09-11T08:26:17.000Z","path":"2019/09/11/论文阅读/一些感兴趣的方向的论文阅读/","text":"面向中文歌词的音乐情感分类方法，2019，北工大引言音乐是情感的载体, 情感是音乐最重要的语义信息, 音乐的情感分析广泛应用于音乐检索、音乐推荐和音乐治疗等领域。歌词文本中确实蕴含着一些特有的语义信息, 包括情感信息。 ​ 歌词本质上属于文本的范畴, 词语的情感判别是歌词情感分析的基础. 构建一部合理的音乐情感词典, 实现词汇的情感分析是歌词情感分析的前提和基础. 国内情感词典构建起步较晚, 情感词典的领域特性也日趋明显. 已有研究构建的情感词典主要集中在中文评论领域, 如微博评论和商品评论, 评论情感分析一般只判别情感极性, 即褒贬性, 而歌词具有更加丰富的情感, 目前还没有被广泛认可的音乐领域的中文情感词典。 基于歌词的音乐情感分类构建情感词表 选择VA模型作为音乐情感分类的依据 结合VA模型建立情感词表 中文音乐情感词典​ 对情感词表进行扩展，构建情感词典。 计算词语相似度构建音乐情感词典 使用《哈工大同义词林》对情感词表进行扩展，构建基础情感词典 结合歌词语料库对基础情感词典做进一步扩展 构建基于歌词的特征向量​ 依照所构建的情感词典获取情感词权值, 基于TF-IDF 构造特征向量, 并进一步考虑词性对情感分类的影响, 将特征向量扩展到16 个维度. 歌词情感分类​ 监督学习，KNN分类算法。 实验结果及分析数据集​ 200篇中文歌词文档，每个类别50篇。每篇歌词的情感标签由多人进行标记，选择标记人数最多的类别作为该歌词的标签。 评价指标​ 本文使用准确率、精确率、召回率和F 值来评价分类效果. 总结 基于情感词典的监督学习算法 数据集是自己收集，手动标注 方法不算新颖，挺简单的 不好做啊","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"}]},{"title":"用PyTorch学习NLP Chapter 3.神经网络基础组件","date":"2019-09-10T06:31:09.000Z","path":"2019/09/10/NLP/Chap.3/","text":"Chapter 3.神经网络基础组件Perceptron: The Simplest Neural Network​ 图解感知机结构：(图的链接是在是太长了，要考虑一下解决办法) ​ 激活函数的选择有很多种，这里选择了Sigmoid函数。 Activation Functions​ 这里列出本书中用到的四个激活函数：(都已经比较熟悉了，就不多做解释了) Sigmod 12x = torch.range(-5, 5, 0.1)y = torch.sigmoid(x) Tanh 12x = torch.range(-5, 5, 0.1)y = torch.tanh(x) ReLU 12x = torch.range(-5, 5, 0.1)y = torch.relu(x) Softmax 123softmax = torch.nn.Softmax(dim=1)x = torch.randn(1,3)y = softmax(x) Loss Functions Mean Squared Error Loss Categorical Cross-Entropy Loss PyTorch中的计算交叉熵的对象的输入是未经过Softmax变换的预测值和各个样本的类标号构成的向量(为转换成One-hot向量) Binary Cross-Entropy 不同于Categorical Cross-Entropy Loss，二元交叉熵的输入是预测值的概率分布和样本的类标号构成的向量 逻辑回归的损失函数实际上就是二元交叉熵损失 Diving Deep into Supervised Training​ 统计学习方法的三要素： 模型 策略(经验风险最小化、结构风险最小化) 算法(BP等等) ​ 完成一个有监督学习任务还需要训练数据。 Putting It Together:Gradient-Based Supervised Learning​ PyTorch完成一个学习过程的步骤如下： 选择模型和用于训练模型的数据 使用名为zero_grad()的函数清除存储在模型对象中的所有信息(如梯度) 模型计算给定输入数据(x_data)的输出(y_pred) 计算损失函数，通过比较模型输出(y_pred)和y_target来计算损失 PyTorch损失对象(criteria)具有一个名为backward()的函数，该函数迭代地通过计算图向后传播损失，并将梯度通知给每个参数 最后，优化器(optim)用一个名为step()的函数指示参数如何在已知梯度的情况下更新参数 至此，完成了一次参数的更新。 Correctly Measuring Model Performance:Splitting the Dataset​ 我们训练模型的最终目标是使模型能够很好的概括数据的真实分布。然而数据有限，所以其实数据的真实分布是不得而知的。因此当模型过度拟合训练数据的分布时，因为训练数据不能够代表全部数据的真实分布，这个时候就会产生过拟合。 ​ 如何避免过拟合(顺便提一嘴)： 增加训练数据 降维 正则化 ​ 如何选择模型： 在训练数据比较充足时，可以将训练数据划分为训练集、验证集和测试集 大多数情况下，训练数据没有那么充裕，这个时候可以使用交叉验证 Knowing When to Stop Training 选择模型训练的epoch数目一般使用启发式发放，一般称为早停止 在每个epoch或每N个epoch结束后，查看模型在验证集上的结果，如果验证集准确率要高于之前的模型，则保留当前训练的模型副本，否则停止训练 将测试性能最优的模型作为最后的训练结果 Regularization L2正则化 在pytorch中，可以通过在优化器(optim)中设置weight_decay参数来控制正则化的程度 结构正则化技术 Dropout L1正则化 鼓励稀疏解 Example：Classifying Sentiment of Restaurant ReviewsThe Yelp Review Dataset​ Yelp评论数据集最初是2015年由Yelp(美国最大的点评网站)举办的文本情感分类比赛中提出的，其中有56万个训练样本和3.8万个测试样本。在这里是选择了10%的训练数据作为完整数据集。 ​ 使用一个小数据集可以快速进行试验，可以使用从较小数据集子集中获得的知识对整个数据集进行重新训练。在训练深度学习模型时，这是一个非常有用的技巧。 通过训练集来得到模型的参数 通过验证集选择最优的超参数 通过测试集对模型进行最终的评估和报告 ​ 在几乎每个实例中， 都使用Vocabulary，Vectorizer和Dataset这三个类来执行一个关键的pipeline：将文本输入转化为小批量的向量。 Understanding PyTorch’s Dataset Representation​ PyTorch通过提供 class Dataset为数据集提供了一个抽象，在对新数据集使用PyTorch时，新的数据集类必须继承Dataset类，并实现getitem和len方法。 ​ 通过针对每个实际的数据集实现继承PyTorch的新的数据集类，允许各种PyTorch程序使用新实现的数据集类。 ​ ReviewDataset Class的结构： __init__() 重写构造函数，为各种变量赋值 self.review_df - 数据集(什么样的数据集？) self._vectorizer - 向量化的数据集 训练集、验证集、测试集变量 其他 @classmethod load_dataset_and_make_vectorizer() 加载数据集并创建向量化的实例 @classmethod 是类的内置函数，它能够自己创建一个类的实例 @classmethod load_dataset_and_load_vectorizer() 加载数据集和向量化的实例 @classmethod 这两个内置函数实际上完成了两个任务 在没有正确格式的数据集和向量时先对数据进行格式化 然后再创建Dataset的实例 @staticmethod load_vectorizer_only() 仅加载向量 save_vectorizer() 将向量化的实例使用json存储到硬盘 get_vectorizer() 返回向量(仅仅是将类的属性返回) get_split() 选择将要处理的数据，并给类的对应属性赋值 __len__(self) 返回要处理数据的size __getitem__() 重写的PyTorch的Dataset类的方法 暂时没看明白是干什么的》。。。 get_num_batcher() 输入批的大小，返回批的数量 The Vocabulary, the Vectorizer, and the DataLoaderVocabulary​ 从文本到向量化的minibatch处理的第一步是将每个token映射到它的向量标号。实现方法是在token和标号之间有一个双向映射。这两个映射被封装到Vocabulary中。 ​ Vocabulary类的结构如下： __init()__ self._token_to_idx 一个完成从token到ID的映射的字典 self._idx_to_token 完成从id到token的映射 to_serializable() 返回一个可以被序列化的字典 @classmethod from_serializable() 从一个序列化的字典(to_serializable返回的对象)中创建Vocabulary实例 add_token() 根据token更改两个映射字典 add_many() 添加许多个token到Vocabulary中 lookup_token() 查找token的index，如果token没出现，就返回UNK的index lookup_index() 查找index对应的token __str__() 返回self的大小(?) __len__() 返回映射的大小 Vectorizer​ ReviewVectorizer()的结构： __init__() self.review_vocab 将词(word)与整数匹配 self.rating_vocab 将类别标签与整数匹配 vectorize() 创建一个review的one-hot向量 @classmethod form_dataframe() 从Dataset 的dataframe结构实例化向量(?究竟干了啥) 创建了一个一样的向量 @classmethod from_serializable() 从serializable dictionary 创建一个评论向量 to_serializable() Create the serializable dictionary for caching Dataloader​ 文本向量化小批处理的最后一个阶段是对向量化的数据分组。PyTorch提供了一个名为DataLoader的内置类来协调这个过程。DataLoader通过提供一个PyTorch数据集、一个batch_size和一些关键字参数来实例化，得到的对象是一个python迭代器。 ​ 本例中，通过在定义函数generate_batcher()中使用DataLoader内置类，来实现batch的迭代。 12def generate_batches(dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"): ...... A Percptron Classifier​ 定义一个ReviewClassifier类，来实现计算模型的预测值。 12class ReviewClassifier(nn.Module): ...... The Training Routine​ 这里的训练模型的历程可以看做一种规范，在深度学习的开发中，可以将这看做一种习惯。 ​ 使用python内置的argparse模块来进行参数的管理： 123from argparse import Namespaceargs = Namespace(......) Setting The Stage For The Training To Begin 初始训练状态 实例化数据集和模型 实例化损失函数和优化器 123456789101112131415161718import torch.optim as optimdef make_train_state(args): ...... train_state = make_train_state(args)# dataset and vectorizerdataset = ReviewDataset.load_dataset_and_make_vectorizer(arts.review_csv)vectorizer = data.get_vectorizer()# model,仅仅给出预测classifier = ReviewClassifier(num_features = len(vectorizer.review_vocab))classifier = classifier.to(args.device)# loss and optimizer， 计算损失并进行优化loss_func = nn.BCEWithLogitsLoss()optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate) The Training Loop​ 训练循环由两个循环组成：内循环覆盖数据集中的mini-batch，另一个外循环重复内循环若干次。在每个内部循环中，计算损失，并使用优化器更新模型参数。 1234567891011121314151617for epoch_index in range(args.num_epoch): # 初始化参数 for batch_index, batch_dict in enumerate(batch_generator): # 1. zero the gradients # 2. compute the output # 3. compute the loss # 4. use loss to produce gradients # 5. use optimizer to take gradient step # compute the accuracy # 在训练完每个epoch之后在计算模型在验证集上的准确率，从而判断是否发生了过拟合 for batch_index, batch_dict in enumerate(batch_generator): # 1. compute the output # 2. compute the loss # 3. compute the accuracy # 结束一个epoch的训练过程，中间过程的结果都被保存到了train_state中 Evaluation, Inference, and InspectionEvaluation, Inference, and Inspection​ 在测试集上进行验证的过程与在验证集上进行计算的过程完全相同。 Inference And Classifying New Data Points​ 在新数据上进行推断，看模型效果如何。 Inspecting Model Weights​ 另一种检查模型在完成训练后是否表现良好的方法是检查权重，对权重是否正确做出判断。 ​ 对当前的这个任务来说这种方法是可行的，但是并不通用。 Summary","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://yyukachiiii.github.io/child/tags/PyTorch/"}]},{"title":"对话系统","date":"2019-09-09T04:24:20.000Z","path":"2019/09/09/论文阅读/人机对话/","text":"人机对话系统综述，2018，哈工大人机对话系统的研究背景及意义​ 人机对话系统的研究最早追溯到1950年，即图灵测试。测试者借助某种装置已对话的方式与人类或对话系统进行交谈，当测试结束后，如果有30%以上的测试者不能正确区分对话系统和人的回复，则称该系统通过了图灵测试，拥有了人的智能。 ​ 人机对话系统的功能分类： 任务型 目的：完成特定任务 应用场景：虚拟个人助理 开放域聊天 目的：闲聊 应用场景：娱乐、情感陪护、营销沟通 知识问答 目的：知识获取 应用场景：客服、教育 推荐 目的：信息推荐 应用场景：个性化推荐 发展历史 最早的人机对话系统：诞生于1966年，由MIT的Joseph Weizenbaum开发的ELIZA 作用：用于在临床治疗中模仿心理医生 1988年，UC Berkeley开发了名为UC(UNIX Consultant)的对话系统 作用：帮助用户学习怎样使用UNIX操作系统 地位：推动了对话系统的智能化程度 Richard S. Wallace在1995年开发了ALICE系统，并与1998年开源 模型和框架​ 一般的人机对话系统通常包括三个关键模块： 口语语言理解(SLU):将用户说出的话转换为结构化的语义表示。 举例：识别出“领域、意图和语义槽(slot)” 对话管理(DM) 定义：综合用户当前输入和历史对话中已获得的信息，给出机器答复的结构化表示。 结构 对话状态追踪(Dialogue State Tracking, DST) 作用：依据SLU的结果，把旧的对话状态更新为新的对话状态 对话策略优化(Dialogue Policy Optimization, DPO) 作用：根据DST维护的对话状态，确定当前状态下如何回复 自然语言生成(NLG) 定义：把DM输出的结构化对话策略还原成对人友好的自然语言 实现技术和方案​ 以上框架是针对任务型对话系统提出的，并不能够很好的应对开放域聊天型对话系统。因为在开放领域中，无法穷举用户的意图和语义槽，也无法穷举可能的回复策略。 ​ 但随着深度学习技术的发展，用户的意图和回复策略等信息可以使用向量隐式的表示。而且可以自动的从大量的对话数据中学习出来。 ​ 任务型和开放域聊天机器人不同模块的对比： 任务型机器人 对话语言理解 领域及意图识别、语义槽识别 对话管理 状态跟踪、对话策略 自然语言生成 基于模板(穷举) 开放域聊天 对话语言理解 主题识别、关键词识别、情感分析 对话管理 记忆网络、对话上下文建模 自然语言生成 基于深度学习的编码-解码 ​ 当前研究热点： 使用深度学习技术实现任务型对话的各个模块 使用端到端技术直接生成自然语言回复 结合外部知识库进行自然语言生成 服务平台​ 开发一个对话系统的步骤： 定义和准备 定义该对话系统支持的领域/意图和问题类型 定义语义槽 进行相关的数据标注 训练和实现 训练领域/意图或问题分类模型 实现语言理解、对话管理和语言生成模块 部署 在自己的服务器上，部署实现好的工程，对用户提供服务 总结及展望​ 当前的人机对话系统的主要问题： 在聊天上如何让机器更像人 在场景化任务中如何做到高效的场景切换 基于多轮交互的人机对话系统综述，2019，中科大引言 单轮对话一般不存在指代省略或上下文连贯性问题 多轮对话中存在人机的多轮交互，对聊天的上下文、指代省略的补全和复杂需求的明确的等问题都有更为复杂的要求 早期的对话系统的研究，基本都是采用基于符号和规则的方法，至今仍然是主流的人机对话系统的解决方案之一 基于多轮交互的人机对话系统主要类型及解决方案任务型对话基于管道的方法​ 任务型对话的一种经典的解决方案，主要结构包括： 自然语言理解 对话管理 对话状态追踪 对话策略学习 自然语言生成 自然语言理解 输入：用户的语句 任务(依次完成) 槽标记(slot tagging) 对句子中的语义槽序列进行标记 语义槽是根据不同的场景预先定义的 大量基于深度神经网络的方法被应用到这个问题上 语义槽 句子级别 用户需求类型 语句类型 词语级别 实体识别 语义槽填充 领域识别(domain detection) 将用户的服务需求划分到某一事先定义好的领域下 意图理解(intent determination) 针对用户的表述中的显示意图和隐示意图做出识别和理解 地位 对话系统中的预处理模块 对话状态追踪 背景 NLU处理过后，形成一个包含用户在本轮对话中所有需求信息的状态信息 地位 确保对话系统健壮性的核心组成部分 核心 利用对话中的信息对预定义的对话的细节框架进行填充 当框架中存在未能填补完成的细节时，系统会向用户做出进一步询问 技术 早期以规则为主 现在已神经网络为主(CNN、RNN) 对话策略学习 目的 利用当前对话状态的表征向量产生下一步最优的回复 解决方案 监督学习 强化学习 特点 学习出一个好的对话生成策略需要大量的训练数据支持 可以通过专家系统的规则作为处事策略进行训练，从而加快模型的训练速度 现状 端到端的强化学习比起监督学习，在各种策略学习中都有较好的结果(？怎么个端到端？) 自然语言生成 目的 将基于抽象的对话策略做出的决策装换成自然语言表述的句子 地位 对于对话系统的自然度有着极为重要的影响 极大地影响人机对话系统的用户体验 解决方案 基于模板和规则 生成效果精确 领域局限性过强，且可扩展性差 基于数据驱动 依旧不够灵活 基于深度学习(基于深度学习不也是基于数据驱动的吗) 基于端到端的方法 基于管道的特点 模块化，构建灵活，分类优化 系统整体优化困难 基于端到端的特点 能够利用更为海量的数据和强大的计算力 可扩展性得到了提升 规避认为特征工程带来的不确定性和工作量 不仅适用于任务型对话系统，对非任务型对话系统同样有很好的结果 基于端到端的缺陷 训练数据过于庞大 单纯使用这一结构会导致对话策略的学习中对对话控制的能力偏弱 非任务型对话​ 非任务型对话是一种面向开放域的人机对话系统，通常不依赖于外部知识库，因为不包含任务型对话的4个基本的自然语言处理组件。 生成方式 检索式 流畅性好，效果易于评估 对上下文敏感度相对不足 生成式 基于端到端学习 对于上下文具有很好的敏感度 难以进行评估，容易产生单调性回复，且具有一定难度 语义鸿沟：两个词语或句子长得像，不代表他们的意思是相近的，即人们平时判断两个句子是不是相似，是通过大量的知识，得到语义层面上的理解，从而进行判断 基于检索的方法 思想 在多个候选回答中选择一个最合适的回答作为输出 核心 已知的对话信息和回复之间的匹配度的确定 基于生成的方法 克服了基于检索的方法对于外部知识的规模限制 Seq2Seq 序列到序列(Sequence-to-Sequence，Seq2Seq)模型又称作编码器-解码器(Encoder-Decoder)模型 HRED模型 基于RNN的Seq2Seq难以保持对较长上文的记忆 缺乏对长期上下文的评估 HREd能够将历史回话信息应用到Seq2Seq结构中，解决了对句子长度的限制 最大化互信息模型(MMI)​ Seq2Seq在预测过程中使用极大似然估计，因此倾向于产生语法上合理而非正确性最佳的“稳妥”回复。 目的 提高信息和回答之间的相互关系 减低对话系统生成的回复中无意义的“稳妥”回复的概率 注意力机制 提出时间 2014年 思想 来源于人类观察环境的习惯规律 模拟人类在观察事物时，只关注重要的局部，获取需要的信息 目的 解决Seq2Seq模型对长句子理解能力较差的问题 强化学习生成模型​ 强化学习能够着眼长远学习最优策略，能够解决Seq2Seq模型短视的问题。同时能够提升生成的回复的多样性，减少了训练过程对于训练语料的需求。 质量评价标准​ 对话系统的评价，一直是研究的重点和难题之一。 特点 评价指标的设计设计多个角度 非任务型对话难以通过某一固定的评价标准来进行衡量 PARADISE 概述 将对话持续时间和其他特征融入线性方程 利用用户满意度的刻画对系统进行评价 结果 虽然考虑因素非常丰富，但是实际效果差强人意甚至存在严重误差 词重叠类评价 描述 通过比较生成的结果和真实的响应之间的信息重合程度作为评价指标，效果缺乏可行性 分类 BLEU(Bilingual Evaluation Understudy，双语评估替换？) 通过比较模型的生成语句和参考答案语句中的n元词组在整个训练语料中共现次数来对生成结果做出评价 METERO 基于BLEU的改进方法，使用WordNet(是由普林斯顿大学的教授建立的特殊的英语词典，是NLP工具包NLTK的组件之一，之前有记录过)计算特定的序列匹配、同义词、词根和词缀、释义之间的匹配关系 ROUGE 词向量评价 描述 通过Word2vec、Sent2Vec等方法将句子转换为向量表示，然后和真实响应的相应表征进行比较 分类 Greedy Matching Embedding Average 人工评价总结与展望 多轮对话效果较差，对话系统的交互效果的优化是一个重要的研究方向 将知识图谱作为外部知识库融入多轮对话系统，能够极大提升对话系统的准确性和流畅度 多轮对话系统的评价标注，如何使用合适的标准完成自动化的对话质量评估 基于深度学习的开放领域对话系统研究综述（高质量综述），2019，北大引言 开放领域聊天机器人，是为了纯聊天或者娱乐而开发的，目的是生成有意义且相关的回复 本文对基于深度学习的实现方法进行全面的回顾和分析 问题描述 背景 历史对话信息 输入 无领域限制的话语 输出 对应的回复语句 多轮对话 需要综合考虑对话上下文，建立对话的长期依赖关系，给出更加符合对话逻辑的回复 定义 在c的背景下，以q为前提，得到语句r作为回复 数据收集 传统的基于规则、模板的开放领域对话系统需要手工制定规则，不需要大规模训练集 数据驱动的方法需要收集大量的对话数据 互联网上大量的记录人类交流的数据，大部分经过预处理之后，都可以被用到开放领域对话系统的训练中 对话数据可以分为人机对话和人人对话，开放领域的对话使用人人对话数据 ​ 人人对话数据的进一步分类： 口语对话 特点：通俗、倾向于使用较短的单词和短语 数据集： Switchboard电话对话数据集 DSTC4-5的Skype通信数据集 康奈尔电影对话语料库 OpenSubtitles网站上的OpenSubtitles数据集 书面对话 特点：用户可以在发送消息前反思他们正在写的东西 数据集： Twitter网站上收集的对话语料 新浪微博上收集的对话语料 聊天软件中收集的关于Ubuntu使用中遇到的问题和相关回答 豆瓣论坛中收集的对话语料 社交网站收集的对话数据虽然容易获取，但是常常包含拼写错误、缩略语等，会对任务造成一定的影响 本文框架深度学习技术 深度学习 机器学习的分支 使用包含复杂结构或由多重非线性变换构成的多处理层计算模型对数据进行高层抽象 神经网络语言模型 语言模型 把语料库当做一个随机变量，对给定前面的词语预测下一个词语的任务建模来计算句子概率 神经网络语言模型 最早由Bengio等人提出 思路： 用一个K维的向量来表示词语 将上行下文词向量序列转换成固定长度的上下文隐藏向量 自编码器 描述 一种无监督的学习模型，由Rumelhart等人最早提出 由编码器和解码器两部分组成，先用编码器对输入数据压缩，再用解码器对数据进行还原，从而实现输入到输出的复现 编码器和解码器基于神经网络构建 变分自编码器 可以用于开放领域的对话系统中，对回复生成的多样性进行控制 卷积神经网络 核心思想 设计局部特征抽取器运用到全局，利用空间相对关系共享参数，提高训练性能 卷积层 从固定大小的窗口中读取输入层数据，经过卷积计算，实现特征提取 CNN在同一层共享卷积计算模型来控制参数规模 池化层 对特征信号进行抽象，缩减输入数据的规模，进行特征压缩 循环神经网络 描述 专门设计用于处理序列数据的神经网络架构 利用时间相对关系减少参数数目以提高训练性能 特点 可以无限循环，理论上能够对任意长度的序列数据进行处理 存在梯度消失问题 在开放域对话中的运用 用于文本表示，输出作为话语的向量表示 序列到序列模型端到端模型 而深度学习模型在训练过程中，从输入端（输入数据）到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层传递（反向传播），每一层的表示都会根据这个误差来做调整，直到模型收敛或达到预期的效果才结束，这是端到端的。 端到端是一种思想，不是采用管道，而是用统一的结构，而序列到序列只是端到端的一种实现，它的模型结构是编码器-解码器。因此二者不是完全等价的概念。 提出 Seq2Seq模型在2014年被先后提出，Cho将其命名为编码器-解码器模型，Sutskever将其命名为序列到序列模型 基本思想 输入一个序列，输出一个序列 模型 一个循环神经网络作为编码器，输入序列转换成定长的向量，将向量视为输入序列的语义表示 一个循环神经网络作为解码器，根据输入序列的语义表示生成输出序列 注意力机制​ 通用的端到端模型，只使用到编码器的最终状态来初始化解码器的初始状态，导致解码器无法学习到句子内的长期依赖关系，同时解码器会随着不断预测出的新词，稀释源输入句子的影响。 描述 可以理解为回溯策略 在当前解码时刻，将解码器RNN前一个时刻的隐藏向量与输入序列关联起来 计算输入的每一步对当前解码的影响程度作为权重 进展 自注意力机制 多头注意力机制 记忆网络 描述 通过在外部存储器模块中存储重要信息来增强神经网络的一类模型 这不就是基于知识库吗？ 生成对抗网络 描述 包含两个模块：生成模型和判别模型 生成模型的训练目标是生成与训练集中真实数据相似的数据 判别模型的训练目标是尽可能的区分真实数据和生成数据 在NLP领域的运用 目标是生成与人类回复无差别的回复 强化学习 描述 智能体通过和环境交互，序列化的做出决策和采取动作，并获得奖赏指导行为的学习机制。 深度强化学习的诞生打破了早期强化学习模型不稳定难收敛的瓶颈 深度强化学习的发展主要有两条路线： DQN(DeepQ-Learning) 策略梯度方法 通过梯度下降方法学习预期奖励的策略参数 更加适合在NLP领域使用 基于深度学习的开放领域对话系统 以大规模对话语料库作为训练语料 利用深度学习算法学习对话模式 分类 单轮对话、多轮对话 检索式、生成式、生成式与检索式相结合的方法 检索式方法 首先构建一个供检索的对话语料库 将用户输入的话语视为对该索引系统的查询，从中选择一个回复 流程 用户在线输入话语 检索并初步召回一批候选回复列表 根据对话匹配模型对候选列表做重排序并输出最佳回复 生成式方法 首先收集大规模对话语料作为训练数据 基于深度神经网络构建端到端的对话模型，学习输入与回复之间的对应模式 回复阶段，系统根据对话模型计算输入语义向量，再逐个生成词语组成回复话语 检索与生成相结合的方法 没仔细说如何结合 深度学习在单轮检索模型中的应用 我的理解 查询：给出提问或者对话，检索：从语料库中选择可能的回复，重排序：从可能的选择中选择最可能的结果 在用户给出第一句话之后 ，我们需要将这句话表示成向量的语义表示，在表示成向量之后，在从语料库中进行匹配，即选择可能的回复，这就是语义融合的过程(?是这样的吗) 流程 对用户输入的查询先检索在重排序给出最佳回复 核心 构建查询-回复的匹配模型 语义表示模型 将查询和回复映射到语义向量 语义融合模型 对查询语义向量和回复语义向量融合过程建模 查询-回复的匹配模型的分类 以表示为中心 以融合为中心 同时建立表示和融合为中心的匹配模型 以表示为中心的框架以融合为中心的框架表示与融合相结合的框架比较分析深度学习在多轮检索模型中的应用 描述 与单轮检索模型类似，多轮检索模型同样遵循检索-匹配-重排序的操作流程 目标 选择既与当前查询相关，又符合历史对话语境的语句作为回复 分类 以表示为中心 以融合为中心 面向重排序 以表示为中心的框架以融合为中心的框架基于重排序的框架分析比较深度学习在单轮生成模型中的应用​ 类比机器翻译技术，将生成回复视为翻译技术。但是由于对话回复多样性的特点，该任务比翻译任务要更加苦难。 ​ 基于深度神经网络模型的生成模型，按照系统实现的基础框架，可以分为： 序列到序列模型框架 神经语言模型框架 强化学习框架 序列到序列模型框架​ 绝大多数的单轮对话生成基于序列到序列模型框架建立端到端的对话模型。 ​ 这里不想涉及太多的技术细节，序列到序列的模型框架是固定的，在之上添加一些注意力等机制。 神经语言模型框架​ 神经语言模型对给定前面的词语能预测下一个词语，所以可以直接基于该框架建立生成式模型。 基于强化学习的学习框架 基于强化学习 基于生成对抗网络 分析比较​ 单轮生成对话任务中使用的深度学习技术包括： 神经语言模型 循环神经网络 注意力机制 对抗生成网络 强化学习 ​ 绝大多数的生成对话的系统还是改进序列到序列框架，改进分为两类： 对模型效果的改进 改进编码器 引入注意力机制 改进解码器 数据校准 对模型效率的改进 使用动态词典提升系统的解码速度 深度学习在多轮生成对话模型中的应用 分类 基于序列到序列模型框架 基于神经语言模型框架 基于层次序列到序列模型框架 序列到序列模型框架 基于基本的序列到序列模型 将对话上下文统一作为输入 融入意图网络的序列到序列模型 结构 编码器 意图识别网络 解码器 多信道编码器 上下文中只有部分短语直接有助于回复生成 在编码器上增加深度信道和宽度信道 利用对偶序列到序列模型进行对话建议 神经语言模型框架 在预测阶段，模型计算概率最大的语句作为回复 层次序列到序列模型框架 基于层次序列到序列模型 基于层次序列到序列模型+记忆网络 分析比较​ 深度学习在多轮对话生成中的应用主要包括： 神经语言模型 序列到序列模型 注意力机制 层次序列到序列模型 ​ 早期的模型大多基于不分层的结构。但是在不分层的框架中，会减弱查询和回复之间的依赖关系。近期的多轮对话生成模型大多基于层次序列到序列模型框架实现。 检索与生成相结合的方法单方法模型分析 基于检索的模型生成的语句质量较高，语法错误少，但是需要大量的对话语料库 生成式对话系统能够创造对话，但是回复质量不可控，设置可能语句不通顺 倾向于生成缺乏语义信息的“万能回复” 生成句子的质量不能够保证 生成式方法的训练和预测的解码过程不一致影响生成质量 检索与生成相结合的方法 使用检索模型检索到的结果和查询同时作为序列到序列模型中编码器的输入生成结果，然后再将该生成结果加入原检索候选集中，重新排序 基于深度学习的开放领域对话系统的关键问题 基于深度学习的开放领域对话系统以数据驱动为基础建立最大化语料库概率的对话模型 回复多样性​ 避免产生合理但是没有意义的回复 话题控制​ 通过引入话题模型改进回复生成的质量 引入外部知识融入情感个性化回复主动对话​ 智能的对话系统应该具备根据对话场景调整对话内容或者主动引入新信息的能力。 开放领域对话系统的评测人工评测不可学习的评测指标检索模型评测指标 召回率 准确率 F1值 平均准确率 R-Precision 生成模型评测指标不需要参考回复的评测指标 困惑度 熵 回复多样性指标 平均回复长度 基于词语重叠的方法 BLEU指标 BLEU-2的指标要好于BLEU-3/4 ROUGE指标 METEOR指标 基于词向量的方法​ 通过Word2vec等方法将句子转换为语义向量，在通过余弦相似度等方法计算生成回复和真实回复之间的语义相似度。 贪婪匹配 平均匹配 向量极值 可学习的评测指标​ 不可学习的评测方法仅利用生成回复自身的特征或信息量来进行评测，没有结合对话上下文语境。新的研究开始训练神经网络评价模型来实现对开放领域对话系统的评价。 监督学习 对抗学习 训练评估系统来代替人工评估员来区分人类回复和系统生成回复 基于深度学习的开放领域对话系统研究趋势展望 基于深度学习提高开放领域对话系统的情感拟人程度 基于深度学习控制开放领域对话系统的回复逻辑 基于深度学习主动把握开放领域对话系统的对话节奏 基于深度学习建立更合理的对话评价机制 通过深度学习模型将检索式和生成式方法更好的整合 使用数据增强技术构建高质量的基准对话数据集 使用深度学习技术构建多模态的开放领域对话系统","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"对话系统","slug":"对话系统","permalink":"http://yyukachiiii.github.io/child/tags/对话系统/"}]},{"title":"文本摘要论文阅读","date":"2019-09-08T11:43:45.000Z","path":"2019/09/08/论文阅读/文本摘要/","text":"文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学引言 任务目的 从一篇或多篇主题相同的文本中抽取能够反映主题的精简压缩版本，帮助用户快速形成对特定主题文本内容的全面了解 任务分类 输入文本数量 单文本摘要方法 多文本摘要方法 抽取方式 抽取式摘要 从原文中不加修改的抽取文本片段组成摘要 生成式摘要 重新组织句子形成比抽取式摘要更加精简的形式 摘要目标 面向查询的摘要(阅读理解？问答？) 一般总结性摘要 领域需求 医学摘要 邮件摘要 …… 文章内容总结 常用数据集总结 做针对数据集的方法总结和分析 总结常用数据集和方法的研究现状、存在的问题 文本摘要常用数据集总体概况​ 文本摘要常用数据集大致可分为两类： 公用数据集 自建数据集 ​ 基于深度神经网络的文本摘要需要较大规模(十万级规模)的训练数据。 DUC/TAC 描述 人工标注的生成式摘要数据集 规模较小(百篇规模),不适用于训练深度神经网络模型 主要方法 基于图模型的方法 基于传统机器学习的方法 Gigaword 描述 由英文新闻文章组成的数据集，包括950万多个新闻源的新闻语料 生成方式 将文章的首句话与新闻提要组成生成式摘要语料库 特点 原句与摘要句都是单个句子 CNN/Daily Mail 描述 单文本摘要语料库 每篇摘要包含多个摘要句 LCSTS(Large scale Chinese Short Text Summatization dataset) 描述 短文本新闻摘要数据库 来源 新浪微博 规模 超过200万 特点 文本篇幅较短 存在噪声 以提出的方法 利用RNN提取生成式摘要 注意力机制 NLPCC(自然语言处理与中文计算会议) 背景 NLPCC是由CCF举办的自然语言文本评测会议，包括文本摘要、情感分析、自动问答等任务 在NLPCC出现的文本摘要任务均为单文本摘要 特点 新闻文本不分领域、不分类型 篇幅较长 已有方法 。。。 自建数据集及其对应方法​ 公用数据集较少，因此基于自建数据集的摘要任务，常用方法可分为： 基于统计的方法 基于图模型的方法 基于词法链的方法 基于篇章结构的方法 基于机器学习的方法 经典算法和最新方法用到的数据集​ 经典方法和最新方法大都是基于深度学习的方法，但是也包括LexRank、TextRank等经典方法。 结论 缺少大规模中文长文本数据集","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"},{"name":"文本摘要","slug":"文本摘要","permalink":"http://yyukachiiii.github.io/child/tags/文本摘要/"}]},{"title":"阅读理解论文阅读","date":"2019-09-08T08:19:55.000Z","path":"2019/09/08/论文阅读/阅读理解/","text":"基于深度学习的机器阅读理解综述，2019，北航引言 定义 让机器学会阅读和理解文章，对于给定的问题，从相关文章中寻找答案 设计技术 语言理解 知识推理 摘要生成 应用 智能搜索：搜索互联网的文档进行阅读理解，为用户返回更加准确和智能的答案 智能客服 发展历史 1999年开始了最早的MRC研究 传统的MRC技术大多采用模式匹配的方法进行特征提取，不能处理表达的多样性问题 先进的MRC技术采用深度神经网络进行机器阅读理解的研究 2016年斯坦福发布大规模数据集SQuAD，极大推动了MRC的快速发展 总结： 历史比较短，研究内容都比较新 基于深度学习的阅读理解 模型的组成 词向量模块 将所有单词映射到一个向量空间，包含单词的语法和语义信息，及词与词之间的关系 编码模块 以词向量表示的文本序列作为输入，通过深度神经网络对文本序列进行特征提取，含有上行下文信息和语义信息 注意力模块 从文章中挑选出与问题关联度最大的部分内容，排除不相关信息 答案预测模块 方法由抽取式逐渐发展为生成式；由单篇文章提供转向多篇文章生成 词向量模块​ 词向量的生成方式： 矩阵分解法 参数学习法 上下文学习法 参数学习法​ 常见的参数学习法： Bengio等基于神经网络的概率语言模型，将词向量作为语言模型的参数进行学习 Mikolov提出的Word2vec模型，借鉴N-gram思想，没有考虑全局信息 ​ 缺陷： 没有解决一词多义的问题 上下文学习法 参数学习法是词向量的一种静态的表示方法，同一个词汇具有相同的词向量表示 解决一词多义问题关键在于利用上下文语境，词向量是动态的模型输出 ​ 上下文学习法学习到的词向量举例： BiLSTM ELMo(Embeddings from Language Models) 注意力机制​ 处理阅读理解问题时，基于神经网络的模型几乎都使用了注意力机制。 ​ 在MRC中，根据注意力机制的结构，可分为： 单路注意力模型 双路注意力模型 自匹配注意力模型 单路注意力模型 描述： 模拟人做阅读理解的过程 只在文章上使用注意力机制 通过结合问题和文本段落二者的信息，生成一个关于文本段落各部分的注意力权重，对文本信息进行加权 双路注意力模型 描述： 同时在问题和文章上使用注意力机制 对文章和问题之间进行了细粒度的建模，一般比单路注意力模型好 自匹配注意力模型 描述 反复阅读文章并找出重点 注意力模块是机器阅读理解的核心模块，对提升模型的性能至关重要 答案预测​ 主要分类： 抽取式 生成式 答案抽取 定义 从文章中挑取答案，然后生成答案 举例 斯坦福大学的SQuAD数据集中，每个问题的答案都是原文的一个子片段，是典型的抽取式数据集 抽取模型 序列模型 边界模型 答案生成 举例 微软亚洲研究院的MS MARCO数据集，答案是人工阅读候选文章后总结生成的，不再受限于文章片段，要求模型具有生成答案的能力 实例 通过答案抽取模型从候选文章中提取线索，然后用机器翻译模型将线索翻译为答案 现状 抽取模型仍是主流，生成技术只是作为一种辅助手段产生答案 MRC面临的主要问题词向量模块仍需改善 使用预训练的语言模型取代预训练的词向量对MRC模型带来了显著的提升 但基于语言模型的词向量仍然有局限性 模型缺乏推理能力 当前的阅读理解模型仍不具备推理能力，而是注意某些线索以执行粗浅的模式匹配 模型缺乏外部知识 模型的信息均来自于文章，没有结合外部知识 答案生成技术研究不足 当前的答案生成技术仍然以抽取式为主，因此在SQuAD数据集上取得了成功 但是在MS MACRO等贴近真实应用场景的数据集仍效果欠佳 MRC的发展趋势 构建端到端的高效模型 深层结构探索，提高推理能力 与其他NLP技术进行结合 外部知识库 指代消解 答案生成技术的深入研究 对多候选文章进行排名 问题 什么是预训练语言模型？ 最新的SQuAD数据集由500+文章和10,0000+问题组成，训练集20MB左右，发展集4MB左右，仅训练数据来看并不大","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"},{"name":"阅读理解","slug":"阅读理解","permalink":"http://yyukachiiii.github.io/child/tags/阅读理解/"}]},{"title":"自动问答论文阅读","date":"2019-09-08T07:07:34.000Z","path":"2019/09/08/论文阅读/自动问答/","text":"自动问答综述，2002，哈尔滨工业大学引言 传统的搜索引擎的不足 相关性信息太多 检索需求无法以几个关键字的逻辑组合来完全表达 以关键字为基础的索引停留的语言层面，没有涉及到语义 自动问答系统 为了改进搜索引擎的弊端发展而来 问答系统就是新一代的搜索引擎 研究概况 早起(上世纪80年代)的问答系统一直被限制在特殊领域的专家系统 组成(三个部分)： 问题分析：理解用户的问题是什么 问题分类 关键词提取 关键词扩展 信息检索：在已有的文档中查找和关键词集相关的文档 答案抽取：从信息检索中返回的网页中抽取答案 最为影响整个问答系统准确性的部分 常问问题(FAQ)库：常问问题可以直接从库中检索并返回 问题分析​ 需要完成的任务： 确定问题的类型 提取出问题的关键词 依据问题的类型对关键词进行适当的扩展 问题分类​ 针对不同类型的问题，有不同的处理方法，例如询问人、询问时间、询问数量等等。 ​ 对问题分类之后，在针对不同的问题类型，制定不同的答案抽取规则。 ​ 问题分类有两种方法： 按照事先规定好的类别进行分类 使用机器学习算法自动分类 关键词提取​ 在问题中，提取出对检索有用的关键字。关键词能够提高检索系统的准确性。 关键词扩展​ 答案中的词常常不是问题的关键词，而是关键词的同义扩展。 ​ 关键词扩展虽然能够提高系统的召回率，但是扩展不当却会降低检索的正确率。 信息检索模块 任务 用前面提取出的关键字到文档库中查找相关的文档 信息检索模块的建立 对文档库进行预处理(汉语要分词、英语要Stemming) 对文档库建立索引 返回内容 文档、段落或句子 答案抽取 任务 将信息检索模块搜索出来的相关文档抽取答案 以句子作为答案​ 步骤如下：（类似于文本摘要呀） 把检索出来的文档分成句子 按照一定的算法，计算每个句子的权重 对句子按照权重进行排序 根据问题的类型对候选答案重新排序 以词或短语作为答案以文摘作为答案​ 多文档自动摘要技术，把相关文档做成文摘，在把文摘返回给用户。 评价​ 建立测试集，将系统对测试集问题得到的回答与人工答案进行对比，计算出问答系统的准确率。 结论 当前(2002年)的问答系统不具备思维和推论能力，只是从文档库中搜索相关的答案。自动问答技术处于起步阶段。 基于Web的问答系统综述","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://yyukachiiii.github.io/child/tags/论文阅读/"},{"name":"问答系统","slug":"问答系统","permalink":"http://yyukachiiii.github.io/child/tags/问答系统/"}]},{"title":"用PyTorch学习NLP Chapter 1.基础介绍","date":"2019-09-06T13:20:36.000Z","path":"2019/09/06/NLP/Chap.1/","text":"Chapter 1.基础介绍The Supervised Learning Paradigm（范例）符号表示 输入(观察值)：$x$ 类别标签(ground truth)：$y$ 类别的预测：$\\hat{y}$ 有价值的内容 实际应用中很少使用随机梯度下降(SGD),因为收敛非常慢 Observation And Target Encoding文本的向量表示的方法 One-Hot Representation 表示成句子或文档长度乘以词表大小的矩阵 表示成一个词汇表长度的向量(一般都是使用这种表示吧…) TF Representation TF表示是构成句子的词的one-hot的总和，即向量中每个条目是相应单词在句子中出现次数的计数 TF-IDF(Inverse Document Frequency) Representation 在TF表示的基础上，惩罚出现次数更多地条目，奖励罕见的符号 这样的启发式表示(?什么是启发式表示？？？)在深度学习中很少使用 Target Encoding 按照目标任务的具体情况选择文本的向量表示 Word Embedding 词向量的分布式表示 Computional Graphs 在计算图中，结点是乘法和加法等数学运算，输入是节点的传入边，输出是结点的传出边。 PyTorch Basics动态计算图 分类 TensorFlow Caffe(贾扬清开发的深度学习框架) Theano 特点 在计算之前，需要声明、编译和执行计算图 计算效率高，在生产中非常有用 静态计算图 分类 PyTorch Chainer DyNet 特点 更加灵活，不需要在每次执行(计算)之前再进行编译 每个输入(什么意思?)可能导致不同的图结构 张量 定义 零阶张量：标量(数字) 一阶张量：向量（数字数组） 二阶张量：矩阵（向量数组）","tags":[{"name":"NLP","slug":"NLP","permalink":"http://yyukachiiii.github.io/child/tags/NLP/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://yyukachiiii.github.io/child/tags/PyTorch/"}]},{"title":"nexmoe","date":"2019-08-29T01:16:49.000Z","path":"2019/08/29/nexmoe/","text":"​ 从零开始学习创建基于hexo框架的主题模型。 前置知识模板引擎定义 模板引擎是为了使用户界面与业务数据（内容）分离而产生的，它可以生成特定格式的文档，用于网站的模板引擎就会生成一个标准的文档. ​ 简单来说，就是将模板文件和数据通过模板引擎生成一个HTML代码。能够让动态页面在渲染的时候，能够简化字符串的拼接操作。 分类 ejs EJS 是一套简单的模板语言，帮你利用普通的 JavaScript 代码生成 HTML 页面。 CSS定义 层叠样式表(Cascading Style Sheets)是一种用来表现HTML（标准通用标记语言的一个应用）或XML（标准通用标记语言的一个子集）等文件样式的计算机语言。 CSS预处理器定义 CSS预处理器是用一种专门的编程语言，进行Web页面样式设计，然后再编译成正常的CSS文件，以供项目使用。 与CSS的关系​ 使用CSS语言之外的语言进行网页样式设计的代码，经过预处理器处理后，转换为标准CSS文件。 代码答疑HEXO辅助函数模板partial 作用：载入其他模板文件，在该代码的位置插入模板文件的代码 代码：&lt;%- partial(layout, [locals], [options]) %&gt; 详细信息 ejs相关代码 &lt;% %&gt;的作用？ 在写网页代码时，有时需要用JavaScript的逻辑代码来渲染页面，但是JavaScript的代码与HTML的代码是不一样的，不好区分。 因此使用&lt;% %&gt;来包裹住逻辑代码，方便与HTML代码进行区分。","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yyukachiiii.github.io/child/tags/hexo/"}]}]