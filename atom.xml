<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SPiCa</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yyukachiiii.github.io/child/"/>
  <updated>2019-09-09T02:33:52.650Z</updated>
  <id>http://yyukachiiii.github.io/child/</id>
  
  <author>
    <name>SPiCa_zY</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>test</title>
    <link href="http://yyukachiiii.github.io/child/2019/09/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/"/>
    <id>http://yyukachiiii.github.io/child/2019/09/08/论文阅读/文本摘要/</id>
    <published>2019-09-08T11:43:45.000Z</published>
    <updated>2019-09-09T02:33:52.650Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学"><a href="#文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学" class="headerlink" title="文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学"></a>文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><ul><li>任务目的<ul><li>从一篇或多篇主题相同的文本中抽取能够反映主题的精简压缩版本，帮助用户快速形成对特定主题文本内容的全面了解</li></ul></li><li>任务分类<ul><li>输入文本数量<ul><li>单文本摘要方法</li><li>多文本摘要方法</li></ul></li><li>抽取方式<ul><li>抽取式摘要<ul><li>从原文中不加修改的抽取文本片段组成摘要</li></ul></li><li>生成式摘要<ul><li>重新组织句子形成比抽取式摘要更加精简的形式</li></ul></li></ul></li><li>摘要目标<ul><li>面向查询的摘要(阅读理解？问答？)</li><li>一般总结性摘要</li></ul></li><li>领域需求<ul><li>医学摘要</li><li>邮件摘要</li><li>……</li></ul></li></ul></li><li>文章内容总结<ul><li>常用数据集总结</li><li>做针对数据集的方法总结和分析</li><li>总结常用数据集和方法的研究现状、存在的问题</li></ul></li></ul><h2 id="文本摘要常用数据集总体概况"><a href="#文本摘要常用数据集总体概况" class="headerlink" title="文本摘要常用数据集总体概况"></a>文本摘要常用数据集总体概况</h2><p>​    文本摘要常用数据集大致可分为两类：</p><ul><li>公用数据集</li><li>自建数据集</li></ul><p>​    基于深度神经网络的文本摘要需要较大规模(十万级规模)的训练数据。</p><h2 id="DUC-TAC"><a href="#DUC-TAC" class="headerlink" title="DUC/TAC"></a>DUC/TAC</h2><ul><li>描述<ul><li>人工标注的生成式摘要数据集</li><li>规模较小(百篇规模),不适用于训练深度神经网络模型</li></ul></li><li>主要方法<ul><li>基于图模型的方法</li><li>基于传统机器学习的方法</li></ul></li></ul><h2 id="Gigaword"><a href="#Gigaword" class="headerlink" title="Gigaword"></a>Gigaword</h2><ul><li>描述<ul><li>由英文新闻文章组成的数据集，包括950万多个新闻源的新闻语料</li></ul></li><li>生成方式<ul><li>将文章的首句话与新闻提要组成生成式摘要语料库</li></ul></li><li>特点<ul><li>原句与摘要句都是单个句子</li></ul></li></ul><h2 id="CNN-Daily-Mail"><a href="#CNN-Daily-Mail" class="headerlink" title="CNN/Daily Mail"></a>CNN/Daily Mail</h2><ul><li>描述<ul><li>单文本摘要语料库</li><li>每篇摘要包含多个摘要句</li></ul></li></ul><h2 id="LCSTS-Large-scale-Chinese-Short-Text-Summatization-dataset"><a href="#LCSTS-Large-scale-Chinese-Short-Text-Summatization-dataset" class="headerlink" title="LCSTS(Large scale Chinese Short Text Summatization dataset)"></a>LCSTS(Large scale Chinese Short Text Summatization dataset)</h2><ul><li>描述<ul><li>短文本新闻摘要数据库</li></ul></li><li>来源<ul><li>新浪微博</li></ul></li><li>规模<ul><li>超过200万</li></ul></li><li>特点<ul><li>文本篇幅较短</li><li>存在噪声</li></ul></li><li>以提出的方法<ul><li>利用RNN提取生成式摘要</li><li>注意力机制</li></ul></li></ul><h2 id="NLPCC-自然语言处理与中文计算会议"><a href="#NLPCC-自然语言处理与中文计算会议" class="headerlink" title="NLPCC(自然语言处理与中文计算会议)"></a>NLPCC(自然语言处理与中文计算会议)</h2><ul><li>背景<ul><li>NLPCC是由CCF举办的自然语言文本评测会议，包括文本摘要、情感分析、自动问答等任务</li><li>在NLPCC出现的文本摘要任务均为单文本摘要</li></ul></li><li>特点<ul><li>新闻文本不分领域、不分类型</li><li>篇幅较长</li></ul></li><li>已有方法<ul><li>。。。</li></ul></li></ul><h2 id="自建数据集及其对应方法"><a href="#自建数据集及其对应方法" class="headerlink" title="自建数据集及其对应方法"></a>自建数据集及其对应方法</h2><p>​    公用数据集较少，因此基于自建数据集的摘要任务，常用方法可分为：</p><ul><li>基于统计的方法</li><li>基于图模型的方法</li><li>基于词法链的方法</li><li>基于篇章结构的方法</li><li>基于机器学习的方法</li></ul><h2 id="经典算法和最新方法用到的数据集"><a href="#经典算法和最新方法用到的数据集" class="headerlink" title="经典算法和最新方法用到的数据集"></a>经典算法和最新方法用到的数据集</h2><p>​    经典方法和最新方法大都是基于深度学习的方法，但是也包括LexRank、TextRank等经典方法。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul><li>缺少大规模中文长文本数据集</li><li></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学&quot;&gt;&lt;a href=&quot;#文本摘要常用数据集和方法研究综述，2019，中科院，中科院大学&quot; class=&quot;headerlink&quot; title=&quot;文本摘要常用数据集和方法研究综述，2019，中科院，中科院大
      
    
    </summary>
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/categories/NLP/"/>
    
      <category term="论文阅读" scheme="http://yyukachiiii.github.io/child/categories/NLP/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/tags/NLP/"/>
    
      <category term="文本摘要" scheme="http://yyukachiiii.github.io/child/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/"/>
    
      <category term="论文阅读" scheme="http://yyukachiiii.github.io/child/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://yyukachiiii.github.io/child/2019/09/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    <id>http://yyukachiiii.github.io/child/2019/09/08/论文阅读/阅读理解/</id>
    <published>2019-09-08T08:19:55.000Z</published>
    <updated>2019-09-08T11:37:36.427Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于深度学习的机器阅读理解综述，2019，北航"><a href="#基于深度学习的机器阅读理解综述，2019，北航" class="headerlink" title="基于深度学习的机器阅读理解综述，2019，北航"></a>基于深度学习的机器阅读理解综述，2019，北航</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><ul><li>定义<ul><li>让机器学会阅读和理解文章，对于给定的问题，从相关文章中寻找答案</li></ul></li><li>设计技术<ul><li>语言理解</li><li>知识推理</li><li>摘要生成</li></ul></li><li>应用<ul><li>智能搜索：搜索互联网的文档进行阅读理解，为用户返回更加准确和智能的答案</li><li>智能客服</li></ul></li></ul><h2 id="发展历史"><a href="#发展历史" class="headerlink" title="发展历史"></a>发展历史</h2><ul><li>1999年开始了最早的MRC研究</li><li>传统的MRC技术大多采用模式匹配的方法进行特征提取，不能处理表达的多样性问题</li><li>先进的MRC技术采用深度神经网络进行机器阅读理解的研究</li><li>2016年斯坦福发布大规模数据集SQuAD，极大推动了MRC的快速发展</li><li>总结：<ul><li>历史比较短，研究内容都比较新</li></ul></li></ul><h2 id="基于深度学习的阅读理解"><a href="#基于深度学习的阅读理解" class="headerlink" title="基于深度学习的阅读理解"></a>基于深度学习的阅读理解</h2><ul><li>模型的组成<ul><li>词向量模块<ul><li>将所有单词映射到一个向量空间，包含单词的语法和语义信息，及词与词之间的关系</li></ul></li><li>编码模块<ul><li>以词向量表示的文本序列作为输入，通过深度神经网络对文本序列进行特征提取，含有上行下文信息和语义信息</li></ul></li><li>注意力模块<ul><li>从文章中挑选出与问题关联度最大的部分内容，排除不相关信息</li></ul></li><li>答案预测模块<ul><li>方法由抽取式逐渐发展为生成式；由单篇文章提供转向多篇文章生成</li></ul></li></ul></li></ul><h3 id="词向量模块"><a href="#词向量模块" class="headerlink" title="词向量模块"></a>词向量模块</h3><p>​    词向量的生成方式：</p><ul><li>矩阵分解法</li><li>参数学习法</li><li>上下文学习法</li></ul><h4 id="参数学习法"><a href="#参数学习法" class="headerlink" title="参数学习法"></a>参数学习法</h4><p>​    常见的参数学习法：</p><ul><li>Bengio等基于神经网络的概率语言模型，将词向量作为语言模型的参数进行学习</li><li>Mikolov提出的Word2vec模型，借鉴N-gram思想，没有考虑全局信息</li></ul><p>​    缺陷：</p><ul><li>没有解决一词多义的问题</li></ul><h4 id="上下文学习法"><a href="#上下文学习法" class="headerlink" title="上下文学习法"></a>上下文学习法</h4><ul><li>参数学习法是词向量的一种静态的表示方法，同一个词汇具有相同的词向量表示</li><li>解决一词多义问题关键在于利用上下文语境，词向量是动态的模型输出</li></ul><p>​    上下文学习法学习到的词向量举例：</p><ul><li>BiLSTM</li><li>ELMo(Embeddings from Language Models)</li></ul><h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>​    处理阅读理解问题时，基于神经网络的模型几乎都使用了注意力机制。</p><p>​    在MRC中，根据注意力机制的结构，可分为：</p><ul><li>单路注意力模型</li><li>双路注意力模型</li><li>自匹配注意力模型</li></ul><h4 id="单路注意力模型"><a href="#单路注意力模型" class="headerlink" title="单路注意力模型"></a>单路注意力模型</h4><ul><li>描述：<ul><li>模拟人做阅读理解的过程</li><li>只在文章上使用注意力机制</li><li>通过结合问题和文本段落二者的信息，生成一个关于文本段落各部分的注意力权重，对文本信息进行加权</li></ul></li></ul><h4 id="双路注意力模型"><a href="#双路注意力模型" class="headerlink" title="双路注意力模型"></a>双路注意力模型</h4><ul><li>描述：<ul><li>同时在问题和文章上使用注意力机制</li><li>对文章和问题之间进行了细粒度的建模，一般比单路注意力模型好</li></ul></li></ul><h4 id="自匹配注意力模型"><a href="#自匹配注意力模型" class="headerlink" title="自匹配注意力模型"></a>自匹配注意力模型</h4><ul><li>描述<ul><li>反复阅读文章并找出重点</li></ul></li><li>注意力模块是机器阅读理解的核心模块，对提升模型的性能至关重要</li></ul><h3 id="答案预测"><a href="#答案预测" class="headerlink" title="答案预测"></a>答案预测</h3><p>​    主要分类：</p><ul><li>抽取式</li><li>生成式</li></ul><h4 id="答案抽取"><a href="#答案抽取" class="headerlink" title="答案抽取"></a>答案抽取</h4><ul><li>定义<ul><li>从文章中挑取答案，然后生成答案</li></ul></li><li>举例<ul><li>斯坦福大学的SQuAD数据集中，每个问题的答案都是原文的一个子片段，是典型的抽取式数据集</li></ul></li><li>抽取模型<ul><li>序列模型</li><li>边界模型</li></ul></li></ul><h4 id="答案生成"><a href="#答案生成" class="headerlink" title="答案生成"></a>答案生成</h4><ul><li>举例<ul><li>微软亚洲研究院的MS MARCO数据集，答案是人工阅读候选文章后总结生成的，不再受限于文章片段，要求模型具有生成答案的能力</li></ul></li><li>实例<ul><li>通过答案抽取模型从候选文章中提取线索，然后用机器翻译模型将线索翻译为答案</li></ul></li><li>现状<ul><li>抽取模型仍是主流，生成技术只是作为一种辅助手段产生答案</li></ul></li></ul><h2 id="MRC面临的主要问题"><a href="#MRC面临的主要问题" class="headerlink" title="MRC面临的主要问题"></a>MRC面临的主要问题</h2><h3 id="词向量模块仍需改善"><a href="#词向量模块仍需改善" class="headerlink" title="词向量模块仍需改善"></a>词向量模块仍需改善</h3><ul><li>使用预训练的语言模型取代预训练的词向量对MRC模型带来了显著的提升</li><li>但基于语言模型的词向量仍然有局限性</li></ul><h3 id="模型缺乏推理能力"><a href="#模型缺乏推理能力" class="headerlink" title="模型缺乏推理能力"></a>模型缺乏推理能力</h3><ul><li>当前的阅读理解模型仍不具备推理能力，而是注意某些线索以执行粗浅的模式匹配</li></ul><h3 id="模型缺乏外部知识"><a href="#模型缺乏外部知识" class="headerlink" title="模型缺乏外部知识"></a>模型缺乏外部知识</h3><ul><li>模型的信息均来自于文章，没有结合外部知识</li></ul><h3 id="答案生成技术研究不足"><a href="#答案生成技术研究不足" class="headerlink" title="答案生成技术研究不足"></a>答案生成技术研究不足</h3><ul><li>当前的答案生成技术仍然以抽取式为主，因此在SQuAD数据集上取得了成功</li><li>但是在MS MACRO等贴近真实应用场景的数据集仍效果欠佳</li></ul><h2 id="MRC的发展趋势"><a href="#MRC的发展趋势" class="headerlink" title="MRC的发展趋势"></a>MRC的发展趋势</h2><ul><li>构建端到端的高效模型</li><li>深层结构探索，提高推理能力</li><li>与其他NLP技术进行结合<ul><li>外部知识库</li><li>指代消解</li></ul></li><li>答案生成技术的深入研究</li><li>对多候选文章进行排名</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li>什么是预训练语言模型？</li><li>最新的SQuAD数据集由500+文章和10,0000+问题组成，训练集20MB左右，发展集4MB左右，仅训练数据来看并不大</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基于深度学习的机器阅读理解综述，2019，北航&quot;&gt;&lt;a href=&quot;#基于深度学习的机器阅读理解综述，2019，北航&quot; class=&quot;headerlink&quot; title=&quot;基于深度学习的机器阅读理解综述，2019，北航&quot;&gt;&lt;/a&gt;基于深度学习的机器阅读理解综述，2
      
    
    </summary>
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/categories/NLP/"/>
    
      <category term="论文阅读" scheme="http://yyukachiiii.github.io/child/categories/NLP/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/tags/NLP/"/>
    
      <category term="论文阅读" scheme="http://yyukachiiii.github.io/child/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
      <category term="阅读理解" scheme="http://yyukachiiii.github.io/child/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://yyukachiiii.github.io/child/2019/09/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E8%87%AA%E5%8A%A8%E9%97%AE%E7%AD%94/"/>
    <id>http://yyukachiiii.github.io/child/2019/09/08/论文阅读/自动问答/</id>
    <published>2019-09-08T07:07:34.000Z</published>
    <updated>2019-09-09T02:33:33.652Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自动问答综述，2002，哈尔滨工业大学"><a href="#自动问答综述，2002，哈尔滨工业大学" class="headerlink" title="自动问答综述，2002，哈尔滨工业大学"></a>自动问答综述，2002，哈尔滨工业大学</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><ul><li>传统的搜索引擎的不足<ul><li>相关性信息太多</li><li>检索需求无法以几个关键字的逻辑组合来完全表达</li><li>以关键字为基础的索引停留的语言层面，没有涉及到语义</li></ul></li><li>自动问答系统<ul><li>为了改进搜索引擎的弊端发展而来</li><li>问答系统就是新一代的搜索引擎</li></ul></li></ul><h2 id="研究概况"><a href="#研究概况" class="headerlink" title="研究概况"></a>研究概况</h2><ul><li>早起(上世纪80年代)的问答系统一直被限制在特殊领域的专家系统</li><li>组成(三个部分)：<ul><li>问题分析：理解用户的问题是什么<ul><li>问题分类</li><li>关键词提取</li><li>关键词扩展</li></ul></li><li>信息检索：在已有的文档中查找和关键词集相关的文档</li><li>答案抽取：从信息检索中返回的网页中抽取答案<ul><li>最为影响整个问答系统准确性的部分</li></ul></li><li>常问问题(FAQ)库：常问问题可以直接从库中检索并返回</li></ul></li></ul><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>​    需要完成的任务：</p><ul><li>确定问题的类型</li><li>提取出问题的关键词</li><li>依据问题的类型对关键词进行适当的扩展</li></ul><h3 id="问题分类"><a href="#问题分类" class="headerlink" title="问题分类"></a>问题分类</h3><p>​    针对不同类型的问题，有不同的处理方法，例如询问人、询问时间、询问数量等等。</p><p>​    对问题分类之后，在针对不同的问题类型，制定不同的答案抽取规则。</p><p>​    问题分类有两种方法：</p><ul><li>按照事先规定好的类别进行分类</li><li>使用机器学习算法自动分类</li></ul><h3 id="关键词提取"><a href="#关键词提取" class="headerlink" title="关键词提取"></a>关键词提取</h3><p>​    在问题中，提取出对检索有用的关键字。关键词能够提高检索系统的准确性。</p><h3 id="关键词扩展"><a href="#关键词扩展" class="headerlink" title="关键词扩展"></a>关键词扩展</h3><p>​    答案中的词常常不是问题的关键词，而是关键词的同义扩展。</p><p>​    关键词扩展虽然能够提高系统的召回率，但是扩展不当却会降低检索的正确率。</p><h2 id="信息检索模块"><a href="#信息检索模块" class="headerlink" title="信息检索模块"></a>信息检索模块</h2><ul><li>任务<ul><li>用前面提取出的关键字到文档库中查找相关的文档</li></ul></li><li>信息检索模块的建立<ul><li>对文档库进行预处理(汉语要分词、英语要Stemming)</li><li>对文档库建立索引</li></ul></li><li>返回内容<ul><li>文档、段落或句子</li></ul></li></ul><h2 id="答案抽取"><a href="#答案抽取" class="headerlink" title="答案抽取"></a>答案抽取</h2><ul><li>任务<ul><li>将信息检索模块搜索出来的相关文档抽取答案</li></ul></li></ul><h3 id="以句子作为答案"><a href="#以句子作为答案" class="headerlink" title="以句子作为答案"></a>以句子作为答案</h3><p>​    步骤如下：<font color="#19caad"><strong>（类似于文本摘要呀）</strong></font></p><ul><li>把检索出来的文档分成句子</li><li>按照一定的算法，计算每个句子的权重</li><li>对句子按照权重进行排序</li><li>根据问题的类型对候选答案重新排序</li></ul><h3 id="以词或短语作为答案"><a href="#以词或短语作为答案" class="headerlink" title="以词或短语作为答案"></a>以词或短语作为答案</h3><h3 id="以文摘作为答案"><a href="#以文摘作为答案" class="headerlink" title="以文摘作为答案"></a>以文摘作为答案</h3><p>​    多文档自动摘要技术，把相关文档做成文摘，在把文摘返回给用户。</p><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>​    建立测试集，将系统对测试集问题得到的回答与人工答案进行对比，计算出问答系统的准确率。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p> 当前(2002年)的问答系统不具备思维和推论能力，只是从文档库中搜索相关的答案。自动问答技术处于起步阶段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;自动问答综述，2002，哈尔滨工业大学&quot;&gt;&lt;a href=&quot;#自动问答综述，2002，哈尔滨工业大学&quot; class=&quot;headerlink&quot; title=&quot;自动问答综述，2002，哈尔滨工业大学&quot;&gt;&lt;/a&gt;自动问答综述，2002，哈尔滨工业大学&lt;/h1&gt;&lt;h2 i
      
    
    </summary>
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/categories/NLP/"/>
    
      <category term="论文阅读" scheme="http://yyukachiiii.github.io/child/categories/NLP/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/tags/NLP/"/>
    
      <category term="论文阅读" scheme="http://yyukachiiii.github.io/child/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
      <category term="问答系统" scheme="http://yyukachiiii.github.io/child/tags/%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Chapter 1.基础介绍</title>
    <link href="http://yyukachiiii.github.io/child/2019/09/06/NLP/Chap.1/"/>
    <id>http://yyukachiiii.github.io/child/2019/09/06/NLP/Chap.1/</id>
    <published>2019-09-06T13:20:36.000Z</published>
    <updated>2019-09-09T02:34:16.619Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-1-基础介绍"><a href="#Chapter-1-基础介绍" class="headerlink" title="Chapter 1.基础介绍"></a>Chapter 1.基础介绍</h1><h4 id="The-Supervised-Learning-Paradigm（范例）"><a href="#The-Supervised-Learning-Paradigm（范例）" class="headerlink" title="The Supervised Learning Paradigm（范例）"></a>The Supervised Learning Paradigm（范例）</h4><h6 id="符号表示"><a href="#符号表示" class="headerlink" title="符号表示"></a>符号表示</h6><ul><li>输入(观察值)：$x$</li><li>类别标签(ground truth)：$y$</li><li>类别的预测：$\hat{y}$</li></ul><h6 id="有价值的内容"><a href="#有价值的内容" class="headerlink" title="有价值的内容"></a>有价值的内容</h6><ul><li>实际应用中很少使用随机梯度下降(SGD),因为收敛非常慢</li></ul><h4 id="Observation-And-Target-Encoding"><a href="#Observation-And-Target-Encoding" class="headerlink" title="Observation And Target Encoding"></a>Observation And Target Encoding</h4><h6 id="文本的向量表示的方法"><a href="#文本的向量表示的方法" class="headerlink" title="文本的向量表示的方法"></a>文本的向量表示的方法</h6><ul><li>One-Hot Representation<ul><li>表示成句子或文档长度乘以词表大小的矩阵</li><li>表示成一个词汇表长度的向量(一般都是使用这种表示吧…)</li></ul></li><li>TF Representation<ul><li>TF表示是构成句子的词的one-hot的总和，即向量中每个条目是相应单词在句子中出现次数的计数</li></ul></li><li>TF-IDF(Inverse Document Frequency) Representation<ul><li>在TF表示的基础上，惩罚出现次数更多地条目，奖励罕见的符号</li><li>这样的启发式表示(?什么是启发式表示？？？)在深度学习中很少使用</li></ul></li><li>Target Encoding<ul><li>按照目标任务的具体情况选择文本的向量表示</li></ul></li><li>Word Embedding<ul><li>词向量的分布式表示</li></ul></li></ul><h4 id="Computional-Graphs"><a href="#Computional-Graphs" class="headerlink" title="Computional Graphs"></a>Computional Graphs</h4><p><img src="pic/ComputionalGraph.png" alt="avatar"></p><ul><li>在计算图中，结点是乘法和加法等数学运算，输入是节点的传入边，输出是结点的传出边。</li></ul><h4 id="PyTorch-Basics"><a href="#PyTorch-Basics" class="headerlink" title="PyTorch Basics"></a>PyTorch Basics</h4><h6 id="动态计算图"><a href="#动态计算图" class="headerlink" title="动态计算图"></a>动态计算图</h6><ul><li><p>分类</p><ul><li>TensorFlow</li><li>Caffe(贾扬清开发的深度学习框架)</li><li>Theano</li></ul></li><li><p>特点</p><ul><li>在计算之前，需要声明、编译和执行计算图</li><li>计算效率高，在生产中非常有用</li></ul></li></ul><h6 id="静态计算图"><a href="#静态计算图" class="headerlink" title="静态计算图"></a>静态计算图</h6><ul><li>分类<ul><li>PyTorch</li><li>Chainer</li><li>DyNet</li></ul></li><li>特点<ul><li>更加灵活，不需要在每次执行(计算)之前再进行编译</li><li>每个输入(什么意思?)可能导致不同的图结构</li></ul></li></ul><h6 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h6><ul><li>定义</li><li>零阶张量：标量(数字)</li><li>一阶张量：向量（数字数组）</li><li>二阶张量：矩阵（向量数组）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Chapter-1-基础介绍&quot;&gt;&lt;a href=&quot;#Chapter-1-基础介绍&quot; class=&quot;headerlink&quot; title=&quot;Chapter 1.基础介绍&quot;&gt;&lt;/a&gt;Chapter 1.基础介绍&lt;/h1&gt;&lt;h4 id=&quot;The-Supervised-Le
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yyukachiiii.github.io/child/tags/NLP/"/>
    
      <category term="PyTorch" scheme="http://yyukachiiii.github.io/child/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>nexmoe</title>
    <link href="http://yyukachiiii.github.io/child/2019/08/29/nexmoe/"/>
    <id>http://yyukachiiii.github.io/child/2019/08/29/nexmoe/</id>
    <published>2019-08-29T01:16:49.000Z</published>
    <updated>2019-09-08T02:45:24.349Z</updated>
    
    <content type="html"><![CDATA[<p>​    从零开始学习创建基于hexo框架的主题模型。</p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="模板引擎"><a href="#模板引擎" class="headerlink" title="模板引擎"></a>模板引擎</h3><h6 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h6><blockquote><p>模板引擎是为了使用户界面与业务数据（内容）分离而产生的，它可以生成特定格式的文档，用于网站的模板引擎就会生成一个标准的文档.</p></blockquote><p>​    简单来说，就是将模板文件和数据通过模板引擎生成一个HTML代码。能够让动态页面在渲染的时候，能够简化字符串的拼接操作。<img src="https://upload-images.jianshu.io/upload_images/8707272-8346cf5c4b91b284.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/871/format/webp" alt="avatar"></p><h6 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h6><ul><li><p>ejs</p><blockquote><p><font color="#19caad">EJS 是一套简单的模板语言，帮你利用普通的 JavaScript 代码生成 HTML 页面。</font></p></blockquote></li></ul><h3 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h3><h6 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h6><blockquote><p>层叠样式表(Cascading Style Sheets)是一种用来表现HTML（标准通用标记语言的一个应用）或XML（标准通用标记语言的一个子集）等文件样式的<font color="#0099ff">计算机语言</font>。</p></blockquote><h3 id="CSS预处理器"><a href="#CSS预处理器" class="headerlink" title="CSS预处理器"></a>CSS预处理器</h3><h6 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h6><blockquote><p>CSS预处理器是用一种专门的编程语言，进行Web页面样式设计，然后再编译成正常的CSS文件，以供项目使用。</p></blockquote><h6 id="与CSS的关系"><a href="#与CSS的关系" class="headerlink" title="与CSS的关系"></a>与CSS的关系</h6><p>​    使用CSS语言之外的语言进行网页样式设计的代码，经过预处理器处理后，转换为标准CSS文件。</p><h2 id="代码答疑"><a href="#代码答疑" class="headerlink" title="代码答疑"></a>代码答疑</h2><h4 id="HEXO辅助函数"><a href="#HEXO辅助函数" class="headerlink" title="HEXO辅助函数"></a>HEXO辅助函数</h4><h5 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h5><h6 id="partial"><a href="#partial" class="headerlink" title="partial"></a>partial</h6><ul><li>作用：载入其他模板文件，在该代码的位置插入模板文件的代码</li><li>代码：<code>&lt;%- partial(layout, [locals], [options]) %&gt;</code></li><li><a href="https://hexo.io/zh-cn/docs/helpers" target="_blank" rel="noopener">详细信息</a></li></ul><h4 id="ejs相关代码"><a href="#ejs相关代码" class="headerlink" title="ejs相关代码"></a>ejs相关代码</h4><ul><li><p>&lt;% %&gt;的作用？</p><blockquote><p>在写网页代码时，有时需要用JavaScript的逻辑代码来渲染页面，但是JavaScript的代码与HTML的代码是不一样的，不好区分。</p><p>因此使用&lt;% %&gt;来包裹住逻辑代码，方便与HTML代码进行区分。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​    从零开始学习创建基于hexo框架的主题模型。&lt;/p&gt;
&lt;h2 id=&quot;前置知识&quot;&gt;&lt;a href=&quot;#前置知识&quot; class=&quot;headerlink&quot; title=&quot;前置知识&quot;&gt;&lt;/a&gt;前置知识&lt;/h2&gt;&lt;h3 id=&quot;模板引擎&quot;&gt;&lt;a href=&quot;#模板引擎&quot; 
      
    
    </summary>
    
    
      <category term="hexo" scheme="http://yyukachiiii.github.io/child/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>hexo主题</title>
    <link href="http://yyukachiiii.github.io/child/2019/08/28/hexo%E4%B8%BB%E9%A2%98/"/>
    <id>http://yyukachiiii.github.io/child/2019/08/28/hexo主题/</id>
    <published>2019-08-28T13:20:36.000Z</published>
    <updated>2019-08-28T14:14:00.496Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
</feed>
